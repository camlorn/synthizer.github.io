<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>The Synthizer Manual</title>
        
        <meta name="robots" content="noindex" />
        
        


        <!-- Custom HTML head -->
        


        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        
        <link rel="icon" href="favicon.svg">
        
        
        <link rel="shortcut icon" href="favicon.png">
        
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        
        <link rel="stylesheet" href="css/print.css" media="print">
        

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        
        <link rel="stylesheet" href="fonts/fonts.css">
        

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="introduction.html"><strong aria-hidden="true">1.</strong> Introduction</a></li><li class="chapter-item expanded affix "><li class="part-title">Python Tutorials</li><li class="chapter-item expanded "><a href="python_tutorials/introduction.html"><strong aria-hidden="true">2.</strong> Introduction</a></li><li class="chapter-item expanded "><a href="python_tutorials/installation.html"><strong aria-hidden="true">3.</strong> Installation</a></li><li class="chapter-item expanded "><a href="python_tutorials/basics.html"><strong aria-hidden="true">4.</strong> A Basic Media Player</a></li><li class="chapter-item expanded "><a href="python_tutorials/linger.html"><strong aria-hidden="true">5.</strong> Configuring Linger</a></li><li class="chapter-item expanded "><a href="python_tutorials/events.html"><strong aria-hidden="true">6.</strong> Events</a></li><li class="chapter-item expanded "><a href="python_tutorials/filters.html"><strong aria-hidden="true">7.</strong> Filters</a></li><li class="chapter-item expanded affix "><li class="part-title">Concepts</li><li class="chapter-item expanded "><a href="concepts/c_api.html"><strong aria-hidden="true">8.</strong> Introduction to the C API</a></li><li class="chapter-item expanded "><a href="concepts/initialization.html"><strong aria-hidden="true">9.</strong> Logging, Initialization, and Shutdown</a></li><li class="chapter-item expanded "><a href="concepts/handles.html"><strong aria-hidden="true">10.</strong> Handles and userdata</a></li><li class="chapter-item expanded "><a href="concepts/audio_in.html"><strong aria-hidden="true">11.</strong> Basics of Audio In Synthizer</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="concepts/context.html"><strong aria-hidden="true">11.1.</strong> The Context</a></li><li class="chapter-item expanded "><a href="concepts/generators.html"><strong aria-hidden="true">11.2.</strong> Introduction to Generators</a></li><li class="chapter-item expanded "><a href="concepts/sources.html"><strong aria-hidden="true">11.3.</strong> Introduction to Sources</a></li><li class="chapter-item expanded "><a href="concepts/properties.html"><strong aria-hidden="true">11.4.</strong> Controlling Object Properties</a></li><li class="chapter-item expanded "><a href="concepts/gain.html"><strong aria-hidden="true">11.5.</strong> Setting Gain/volume</a></li><li class="chapter-item expanded "><a href="concepts/pausing.html"><strong aria-hidden="true">11.6.</strong> Pausing and Resuming Playback</a></li><li class="chapter-item expanded "><a href="concepts/lingering.html"><strong aria-hidden="true">11.7.</strong> Configuring Objects to Continue Playing Until Silent</a></li><li class="chapter-item expanded "><a href="concepts/decoding.html"><strong aria-hidden="true">11.8.</strong> Streams and Decoding Audio Data</a></li><li class="chapter-item expanded "><a href="concepts/libsndfile.html"><strong aria-hidden="true">11.9.</strong> Loading Libsndfile</a></li><li class="chapter-item expanded "><a href="concepts/custom_streams.html"><strong aria-hidden="true">11.10.</strong> Implementing Custom Streams and Custom Stream Protocols</a></li><li class="chapter-item expanded "><a href="concepts/channel_mixing.html"><strong aria-hidden="true">11.11.</strong> Channel Upmixing and Downmixing </a></li></ol></li><li class="chapter-item expanded "><a href="concepts/3d_audio.html"><strong aria-hidden="true">12.</strong> 3D Audio, Panning, and HRTF</a></li><li class="chapter-item expanded "><a href="concepts/filters_and_effects.html"><strong aria-hidden="true">13.</strong> Filters and Effects</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="concepts/filters.html"><strong aria-hidden="true">13.1.</strong> Filters</a></li><li class="chapter-item expanded "><a href="concepts/effects.html"><strong aria-hidden="true">13.2.</strong> Effects and Effect Routing</a></li></ol></li><li class="chapter-item expanded "><a href="concepts/events.html"><strong aria-hidden="true">14.</strong> Events</a></li><li class="chapter-item expanded "><a href="concepts/stability.html"><strong aria-hidden="true">15.</strong> Stability Guarantees</a></li><li class="chapter-item expanded affix "><li class="part-title">The Object Reference</li><li class="chapter-item expanded "><a href="object_reference/context.html"><strong aria-hidden="true">16.</strong> Context</a></li><li class="chapter-item expanded "><a href="object_reference/buffer.html"><strong aria-hidden="true">17.</strong> Buffer</a></li><li class="spacer"></li><li class="chapter-item expanded "><a href="object_reference/source.html"><strong aria-hidden="true">18.</strong> Operations Common to All Sources</a></li><li class="chapter-item expanded "><a href="object_reference/direct_source.html"><strong aria-hidden="true">19.</strong> DirectSource</a></li><li class="chapter-item expanded "><a href="object_reference/spatialized_source.html"><strong aria-hidden="true">20.</strong> Operations Common to Panned and 3D Sources</a></li><li class="chapter-item expanded "><a href="object_reference/panned_source.html"><strong aria-hidden="true">21.</strong> PannedSource</a></li><li class="chapter-item expanded "><a href="object_reference/source_3d.html"><strong aria-hidden="true">22.</strong> Source3D</a></li><li class="spacer"></li><li class="chapter-item expanded "><a href="object_reference/generator.html"><strong aria-hidden="true">23.</strong> Operations Common to All Generators</a></li><li class="chapter-item expanded "><a href="object_reference/streaming_generator.html"><strong aria-hidden="true">24.</strong> StreamingGenerator</a></li><li class="chapter-item expanded "><a href="object_reference/buffer_generator.html"><strong aria-hidden="true">25.</strong> BufferGenerator</a></li><li class="chapter-item expanded "><a href="object_reference/noise_generator.html"><strong aria-hidden="true">26.</strong> NoiseGenerator</a></li><li class="spacer"></li><li class="chapter-item expanded "><a href="object_reference/global_effect.html"><strong aria-hidden="true">27.</strong> Operations Common to All Effects</a></li><li class="chapter-item expanded "><a href="object_reference/global_echo.html"><strong aria-hidden="true">28.</strong> GlobalEcho</a></li><li class="chapter-item expanded "><a href="object_reference/global_fdn_reverb.html"><strong aria-hidden="true">29.</strong> GlobalFdnReverb</a></li><li class="chapter-item expanded affix "><li class="part-title">Appendecies</li><li class="chapter-item expanded "><a href="appendices/audio_eq_cookbook.html"><strong aria-hidden="true">30.</strong> Audio EQ Cookbook</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                        
                    </div>

                    <h1 class="menu-title">The Synthizer Manual</h1>

                    <div class="right-buttons">
                        
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        
                        
                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" name="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<h1 id="introduction-1"><a class="header" href="#introduction-1">Introduction</a></h1>
<p>The following tutorials demonstrate installation and basic Synthizer usage
through the Python bindings, in order to let you get a basic feel for the
library.  This manual primarily documents from the perspective of the C API,
since it is infeasible to write a version of this manual for every binding that
might exist.  In general the C API maps to the Python bindings in a
straightforward fashion, though resources prevent maintaining a fully documented
Python API reference.</p>
<p>Nonetheless these tutorials privilege Python.  The Python bindings are special
for two reasons: first, they're the official way I test Synthizer, and thus
always up to date.  Second, they're a good way to show how the various Synthizer
pieces fit together without having to also demonstrate C-style error checking
and similar boilerplate that gets in the way of learning.</p>
<h1 id="installation"><a class="header" href="#installation">Installation</a></h1>
<p>We support Python 3.8 and later.  To install the Python bindings:</p>
<pre><code class="language-bash">pip install synthizer
</code></pre>
<p>Note the following platform specific information:</p>
<p>On Windows, wheels for both 32-bit and 64-bit Python are uploaded to Pypi and no
build step is required.</p>
<p>On Linux, and mac, the Python bindings build themselves from source using a
vendored copy of Synthizer. Additionally, Linux requires the latest version of
gcc and g++, and Mac requires xcode.  CI currently tests against the latest
version of oSX supported by GitHub Actions, Ubuntu 18, and Ubuntu 20.</p>
<h1 id="a-basic-media-player"><a class="header" href="#a-basic-media-player">A Basic Media Player</a></h1>
<h2 id="introduction-2"><a class="header" href="#introduction-2">Introduction</a></h2>
<p>This tutorial demonstrates the basics of Synthizer by explaining all of the
information necessary to build a basic 3D media player with HRTF enabled.</p>
<h2 id="initializing-synthizer"><a class="header" href="#initializing-synthizer">Initializing Synthizer</a></h2>
<p>Synthizer requires initialization and deinitialization. The best way to
initialize Synthizer is to use the context manager:</p>
<pre><code class="language-python">with synthizer.initialized():
    # Code...
</code></pre>
<p>The context manager will handle deinitialization on exceptions.  Though
<code>synthizer.initialize()</code> and <code>synthizer.shutdown()</code> are exposed, use is
discouraged as the context manager ensures clean shutdown in (almost) all cases.</p>
<p>Once the library is deinitialized, calls into Synthizer error.</p>
<p>the context manager forwards all arguments to <code>synthizer.initialize</code>, so e.g.
you can <a href="python_tutorials/../concepts/libsndfile.html">load libsndfile</a> by passing
<code>libsndfile_path</code>.</p>
<h2 id="destroying-objects"><a class="header" href="#destroying-objects">Destroying Objects</a></h2>
<p>Unlike the rest of Python, Synthizer objects represent concrete audio
architecture, which need to have a defined lifetime in order to control when
they are and aren't being heard, and also to ensure that it can be well
understood when things are and aren't using system resources.  To that end,
Synthizer objects don't interact with Python garbage collection. When you're
done with an object, call <code>myobj.dec_ref()</code>.</p>
<p>At the moment, failing to do so will permanently leak the object.  Work in
future may lift this restriction, but it's still necessary to be explicit: if
you aren't, things may be audioble longer than you intend.</p>
<p>Be careful here.  If you leak objects, you will eventually run out of memory. If
you intentionally leak objects and the Python bindings start garbage collecting
them, your program will stop working.</p>
<h2 id="the-context"><a class="header" href="#the-context">The Context</a></h2>
<p>Most objects in Synthizer require a context, which represents a listener in 3D
space, an audio output device, and other miscellaneous infrastructure. Objects
are passed a context on construction, and two objects from different contexts
never interact.</p>
<p>To get a context:</p>
<pre><code class="language-python">ctx = synthizer.Context()
</code></pre>
<p>Currently, selecting audio output devices isn't supported, and audio will go to
the system default.</p>
<h2 id="buffers-streams-and-generators"><a class="header" href="#buffers-streams-and-generators">Buffers, Streams, and Generators</a></h2>
<p>The Synthizer audio graph is as follows:</p>
<ul>
<li>A source is fed by one or more generators and pans audio.</li>
<li>All the sources feed the context's output.</li>
</ul>
<p>Generators are an abstract concept, which represents somewhere audio comes from.
Specific kinds of generators implement the abstract interface in a concrete
fashion, notably <code>BufferGenerator</code> (takes a buffer) and <code>StreamingGenerator</code>
(takes streaming parameters).</p>
<p>The easiest way to get audio into Synthizer is via <code>from_file</code> on various
objects.  Buffers additionally offer a <code>from_encoded_data</code> for passing in-memory
encoded assets, and a <code>from_float_array</code> for passing in float audio data
directly.  It is also possible to access the <code>StreamHandle</code> class and use the
protocol/path pairs as discussed in the <a href="python_tutorials/../concepts/decoding.html">section on
decoding</a> and to <a href="python_tutorials/../concepts/custom_streams.html">implement custom
streams</a>, though tutorials do not exist for these
advanced concepts and you are encouraged to read the examples in <a href="https://github.com/synthizer/synthizer">Synthizer's
repository</a> or the Python binding's
source code to learn how they work.</p>
<p>To play back a stream, you have two choices: <code>StreamingGenerator</code> and
<code>BufferGenerator</code>.</p>
<p><code>Buffer</code>s are in-memory decoded assets, essentially arrays of 16-bit samples
resampled to Synthizer's samplerate. Note that they aren't actually contiguous
arrays, which means that users can't simply copy memory to retrieve the data.
They're also immutable: if you want them to contain different data, you have to
make a new one.  They can be connected to a <code>BufferGenerator</code> in order to
efficiently play back audio.  This is the lowest latency and most efficient way
to play audio.</p>
<p>By contrast, <code>StreamingGenerator</code> is for cases in which it is necessary or
desirable to decode audio in a streaming fashion.  This is useful for music, as
a concrete example.  It comes at the cost of higher audio latency.  For details
on this latency, see <a href="python_tutorials/../object_reference/streaming_generator.html">the
reference</a>.</p>
<p>To get a streaming generator:</p>
<pre><code class="language-python">generator = synthizer.StreamingGenerator.from_file(ctx, &quot;test.wav&quot;)
</code></pre>
<p>To get a <code>Buffer</code> from a file and connect it to a <code>BufferGenerator</code>:</p>
<pre><code class="language-python">buffer = synthizer.Buffer.from_file(&quot;test.wav&quot;)
generator = synthizer.BufferGenerator(ctx)
generator.buffer = buffer
</code></pre>
<p>Note the following:</p>
<ul>
<li>Buffers aren't associated with a context and can be used anywhere,.</li>
<li>Buffers can be used simultaneously by multiple generators (or whatever else).
You are encouraged to cache them and reuse them indefinitely.</li>
<li>When Synthizer needs to overload a constructor, it does so as staticmethods on
the class, and makes it impossible to initialize the class directly.</li>
</ul>
<h2 id="sources"><a class="header" href="#sources">Sources</a></h2>
<p>Sources represent audio output.  They get one or more generators, combine them
all, and output.  Currently we have the following kinds of sources:</p>
<ul>
<li>A <code>DirectSource</code> conneccts audio directly to the speakers, so that you can
pass things through without collapsing them to mono.  This is what you want
for music.</li>
<li>A <code>PannedSource</code> is manually controlled using azimuth and elevation or,
alternatively, a panning scalar where -1 is all left and 1 is all right.</li>
<li><code>Source3D</code> is a 3D environmental source with the usual things you'd expect:
distance model, position, etc.</li>
</ul>
<h2 id="properties"><a class="header" href="#properties">Properties</a></h2>
<p>Synthizer objects are controlled primarily through properties, which are like
knobs on a hardware controller or sliders in a DAW.  They map to Python
properties as properties, e.g. to set one use <code>obj.property = value</code>.
Synthizer's C API represents these as <code>SYZ_P_PROPERTY_NAME</code> constants, which
become <code>property_name</code> in Python.</p>
<p>Synthizer offers the following kinds of properties:</p>
<ul>
<li>int, represented as either a Python integer type or an enum. An example of the
latter case is <code>source.distance_model</code>, which is a <code>synthizer.DistanceModel</code>.
Synthizer exposes enums as Python 3.4-style enums.</li>
<li>Double, which is self-explanatory.</li>
<li>Double3, which is a tuple of 3 doubles. Usually used as a position.</li>
<li>Double6, a tuple of 6 doubles. Usually used as an orientation (given a
dedicated section below).</li>
<li>Object, i.e. <code>buffer_generator.buffer = b</code>.</li>
<li>Biquad, which represents a filter.  See <a href="python_tutorials/./filters.html">the dedicated
tutorial</a>.</li>
</ul>
<p>It is important to note that Synthizer properties are eventually consistent.
What this means is that code like the following doesn't do what you expect:</p>
<pre><code class="language-python">myobj.property = 0
myobj.property += 5
# May leave the property set at 5 forever.
myobj.property += 5
# May or may not fail, depending on timing.
assert myobj.property == 10

myobj.property = 15
x = myobj.property
# may or may not fail depending on timing.
assert x == 15
</code></pre>
<p>Property reads are primarily useful for properties like <code>playback_position</code> on
various generators, where Synthizer is updating the property itself. In general,
it's best to use properties to tell Synthizer what to do, but keep the model of
what's supposed to be going on in your code. A common mistake is to try to use
Synthizer to store data, for example putting the position of your objects in a
source rather than maintaing the coordinates yourself.  For some very simple
rules that will ensure you avoid these bugs:</p>
<ul>
<li>Always set properties with <code>=</code>.</li>
<li>Never read them unless it's something Synthizer also controls, like
<code>playback_position</code>.</li>
</ul>
<p>Object properties are internally referenced in a weak fashion. That is to say
that destroying (<code>.dec_ref()</code>)the object the property is set to will clear the
property.  If this is a <code>Buffer</code> on a <code>BufferGenerator</code>, the generator will
become silent unless a new buffer is assigned.</p>
<h2 id="an-aside-orientation-formulas"><a class="header" href="#an-aside-orientation-formulas">An aside: orientation formulas</a></h2>
<p>Before going much further, most people seem to eventually ask about trigonometry
with respect to using a 3D audio library for 2D games. The high level overview
for those who already know trigonometry is that Synthizer's coordinate system is
right-handed and orientations consist of 2 orthogonal unit vectors <code>(atx, aty, atz, upx, upy, upz)</code> stored as a packed property so that they can both be set
atomically.  But the longer version for those who don't know trigonometry is:</p>
<p>Degrees to radians is:</p>
<pre><code class="language-python">import math

def deg2rad(angle):
    return (angle / 180.0) * math.pi
</code></pre>
<p>People who don't know trig usually ask for orientations that are clockwise of
north. To do that:</p>
<pre><code class="language-python">import math

def make_orientation(degrees):
    rad = deg2rad(angle)
    return (math.sin(rad), math.cos(rad), 0, 0, 0, 1)
</code></pre>
<p>Setting <code>context.orientation</code> to the result of the above will set things up so
that you can treat positive x as east, positive y as north, and positive z as
up. The default orientation faces the listener north.</p>
<h2 id="putting-it-together"><a class="header" href="#putting-it-together">Putting it Together</a></h2>
<p>To play a source in 3D space, do the following:</p>
<ul>
<li>Create a context.</li>
<li>Create a source.</li>
<li>Create a buffer.</li>
<li>Create a generator.</li>
<li><code>generator.buffer = buffer</code></li>
<li><code>source.add_generator(generator)</code></li>
<li>Then manipulate position, etc. on the source.</li>
</ul>
<p>Note that while this list is lengthy, each step is exactly one line of code, and
it is possible to write a function which makes creating sources very easy:</p>
<pre><code>def make_source(context, file_path):
    buffer = synthizer.Buffer.from_file(context, file_path)
    generator = synthizer.BufferGenerator(context)
    generator.buffer = buffer
    source = synthizer.Sourec3D(context)
    source.add_generator(generator)
    return (buffer, generator, soruce)

(buffer, generator, source) = make_source(context, &quot;the_file.wav&quot;)
</code></pre>
<h2 id="turning-hrtf-on"><a class="header" href="#turning-hrtf-on">Turning HRTF On</a></h2>
<p>As explained in the section on <a href="python_tutorials/../concepts/3d_audio.html">3D Audio</a>, HRTF has to
be off by default because we can't detect if the user is using headphones.  To
enable HRTF:</p>
<pre><code>context.default_panner_strategy = synthizer.PannerStrategy.HRTF
</code></pre>
<p>The <a href="python_tutorials/../concepts/3d_audio.html">page on 3D audio</a> also explains a lot of other
useful stuff about 3D audio, and is worth reading even though it isn't
specifically for Python.</p>
<h2 id="a-worked-example"><a class="header" href="#a-worked-example">A Worked Example</a></h2>
<p>The following is a 3D media player, the audio library equivalent of hello world.
It supports the following commands:</p>
<ul>
<li><code>pause</code>, <code>play</code>: pause/play the source</li>
<li><code>seek &lt;seconds&gt;</code>: self-explanatory.</li>
<li><code>pos &lt;x&gt; &lt;y&gt; &lt;z&gt;</code>: move the source. X is right, y is forward, z is up.</li>
<li><code>loop</code>: Toggle looping of the generator.</li>
<li><code>gain &lt;value&gt;</code>: Control the gain of the generator, in DB.</li>
<li><code>quit</code>: self-explanatory.</li>
</ul>
<p>Note that the default distance model parameters cause the source to become
completely silent at around 50 units out. Movements close to the head won't
change the volume much.</p>
<p>This example also doesn't demonstrate destruction, as that's handled by library
deinitialization and process shutdown. A proper program needs <code>source.dec_ref()</code>
etc for dynamic sources, as explained above.</p>
<p>The code:</p>
<pre><code class="language-python">&quot;&quot;&quot;A simple media player, demonstrating the Synthizer basics.&quot;&quot;&quot;

import sys

import synthizer

if len(sys.argv) != 2:
    print(f&quot;Usage: {sys.argv[0]} &lt;file&gt;&quot;)
    sys.exit(1)

with synthizer.initialized(
    log_level=synthizer.LogLevel.DEBUG, logging_backend=synthizer.LoggingBackend.STDERR
):
    # Get our context, which almost everything requires.
    # This starts the audio threads.
    ctx = synthizer.Context()
    # Enable HRTF as the default panning strategy before making a source
    ctx.default_panner_strategy = synthizer.PannerStrategy.HRTF

    # A BufferGenerator plays back a buffer:
    generator = synthizer.BufferGenerator(ctx)
    # A buffer holds audio data. We read from the specified file:
    buffer = synthizer.Buffer.from_file(sys.argv[1])
    # Tell the generator to use the buffer.
    generator.buffer = buffer
    # A Source3D is a 3D source, as you'd expect.
    source = synthizer.Source3D(ctx)
    # It'll play the BufferGenerator.
    source.add_generator(generator)
    # Keep track of looping, since property reads are expensive:
    looping = False

    # A simple command parser.
    while True:
        cmd = input(&quot;Command: &quot;)
        cmd = cmd.split()
        if len(cmd) == 0:
            continue
        if cmd[0] == &quot;pause&quot;:
            source.pause()
        elif cmd[0] == &quot;play&quot;:
            source.play()
        elif cmd[0] == &quot;pos&quot;:
            if len(cmd) &lt; 4:
                print(&quot;Syntax: pos x y z&quot;)
                continue
            try:
                x, y, z = [float(i) for i in cmd[1:]]
            except ValueError:
                print(&quot;Unable to parse coordinates&quot;)
                continue
            source.position = (x, y, z)
        elif cmd[0] == &quot;seek&quot;:
            if len(cmd) != 2:
                print(&quot;Syntax: seek &lt;seconds&gt;&quot;)
                continue
            try:
                pos = float(cmd[1])
            except ValueError:
                print(&quot;Unable to parse position&quot;)
                continue
            try:
                generator.playback_position = pos
            except synthizer.SynthizerError as e:
                print(e)
        elif cmd[0] == &quot;quit&quot;:
            break
        elif cmd[0] == &quot;loop&quot;:
            looping = not looping
            generator.looping = looping
            print(&quot;Looping&quot; if looping else &quot;Not looping&quot;)
        elif cmd[0] == &quot;gain&quot;:
            if len(cmd) != 2:
                print(&quot;Syntax: gain &lt;value&gt;&quot;)
                continue
            try:
                value = float(cmd[1])
            except ValueError:
                print(&quot;Unable to parse value.&quot;)
                continue
            # Convert to scalar gain from db.
            gain = 10 ** (value / 20)
            source.gain = gain
        else:
            print(&quot;Unrecognized command&quot;)
</code></pre>
<h1 id="configuring-linger"><a class="header" href="#configuring-linger">Configuring Linger</a></h1>
<p>As explained in the next section, Python exposes Synthizer events.  Prior to
0.9, events were a way to make sure that generators were destroyed after they
finished playing.  0.9, however, introduced <a href="python_tutorials/../concepts/lingering.html">a better
mechanism</a>, which allows one to configure an object to
stick around until it's &quot;finished&quot;.  To configure this in Python:</p>
<pre><code>generator.config_delete_behavior(linger=True)
</code></pre>
<p>Other keyword arguments to <code>config_delete_behavior</code> correspond to other fields
on <code>syz_DeleteBehaviorConfig</code>, which is explained
<a href="python_tutorials/../concepts/lingering.html">here</a>.</p>
<p>This isn't enabled by default because it is more important for applications to
be aware of the resources they are using, and making <code>destroy()</code> destroy the
object nearly immediately allows for this clarity.  Additionally, enabling it on
extremely long sounds is generally not the desired effect (in that case you also
want to pass <code>linger_timeout</code>).  That said, it is efficient enough to be used
without restriction.</p>
<p>The object reference explains what each object does when lingering.</p>
<h1 id="events"><a class="header" href="#events">Events</a></h1>
<p>Synthizer supports sending events.  Currently, it can send finished and looped
events for both <code>BufferGenerator</code> and <code>StreamingGenerator</code>.  This will be
extended to other objects and concepts in future, as appropriate.  The events
have the following meanings:</p>
<ul>
<li>Finished: the generator isn't configured to loop and has reached the end.</li>
<li>Looped: The generator is configured to loop, and a loop was just completed.</li>
</ul>
<p>Events are disabled by default and must be enabled.  An additional keyword
argument <code>enable_events = True</code> can be passed to the Context constructor.</p>
<p>Once enabled, events feed a queue that must be polled forever.  If events are
enabled and the application never polls the queue, the queue will fill up
forever; this is effectively a memory leak.  In other words, only enable events
if you know you'll actually use them.</p>
<p>The events system will drop events which would refer to a destroyed object.
Destroying a generator before seeing its finished event, for instance, means
you'll never see it.</p>
<p>Events are exposed as an iterator on the context:</p>
<pre><code>for event in ctx.get_events():
    if isinstance(e, synthizer.FinishedEvent):
        # Handle finished
    elif isinstance(e, synthizer.LoopedEvent):
        # process
</code></pre>
<p>The iterator returned from <code>get_events</code> takes an optional argument to limit the
number of events returned in one iteration.  By default, it's unlimited, and
will stop returning events as soon as none are available (in other words: it
never blocks and can be used in game loops).</p>
<p>As shown above, you detect event types with <code>isinstance</code>.  Each event has a
<code>source</code> and <code>context</code> property indicating the source (e.g. generator) and
context associated with it, as Synthizer objects. In future, other event types
may include more information.</p>
<h1 id="filters-in-python"><a class="header" href="#filters-in-python">Filters in Python</a></h1>
<p>Synthizer offers the ability to set filters in many places, in order to allow
for precise control over audio effects.  By far the most useful of these is on
all sources, which can be used to simulate occlusion.  Some places filters may
be found are:</p>
<ul>
<li>All source types, as:
<ul>
<li>A <code>filter</code> property, which applies to all audio coming out of the source.</li>
<li>A <code>filter_direct</code> property, which runs after <code>filter</code> but only to audio
going to the direct path (e.g. not through effects).</li>
<li>a <code>filter_effects</code> property, which also runs after <code>filter</code> but only on
audio going to effects.</li>
</ul>
</li>
<li>On all effects, as a <code>filter_input</code> property, which filters the input to an
effect.</li>
<li>As a <code>filter</code> parameter to <code>Context.config_route</code>, which will apply to audio
traveling through that effect send.</li>
</ul>
<p>There are basically two paths, as to how audio can get filtered.  First is
<code>filter</code> followed by <code>filter_direct</code>.  Second is <code>filter</code>, <code>filter_effects</code>, the
filter on the send, then <code>filter_input</code> on the effect.  <code>filter</code> is on both
paths so that it can be used to control the audio from the source.</p>
<p>practically, occlusion goes on either <code>filter</code> or <code>filter_direct</code> depending if
you want it fed into reverb, <code>filter_input</code> on reverbs provides a per-reverb
coloration of the &quot;walls&quot;, and the filter in the effect send can be used to
provide per-source coloration for the effect that it's going to.</p>
<p>Currently, the properties are readonly until such time as Synthizer makes
<code>struct syz_BiquadConfig</code> non-opaque.</p>
<p>Synthizer supports lowpass, bandpass, and highpass filters.  You get them as
follows:</p>
<pre><code>source.filter = synthizer.BiquadConfig.design_lowpass(frequency, q)
source.filter = synthizer.BiquadConfig.design_highpass(frequency, q)
source.filter = synthizer.BiquadConfig.design_bandpass(frequency, bandwidth)

context.config_route(output, input, filter = synthizer.BiquadConfig.design_lowpass(1000))
</code></pre>
<p>In the above, <code>q</code> is an advanced parameter that defaults to a value which yields
a butterworth filter, which is almost always what you want.  You shouldn't need
to change it from the default, and can usually just omit it.  <code>q</code> controls
resonance. higher values of <code>q</code> produce filters that ring, which may or may not
be beneficial for designing audio effects.</p>
<p>To clear a filter, set it to <code>synthizer.BiquadConfig.design_identity()</code>, which
is how you get the filter which does nothing to the audio (internally Synthizer
will avoid running it, but filters do not have a concept of NULL).</p>
<p>Note that not all filter configurations are stable.  Synthizer cannot validate
this case in any meaningful fashion.  All normal usage should work as expected,
but extreme values may produce unstable filters.  For example: lowpasses with
absurdly high frequencies, bandpasses with a bandwidth of 1 HZ, and/or very low
and very high <code>q</code> values. For those not already familiar with unstable filters,
this case can be recognized by strange metallic ringing effects that run
forever, even when audio is silent.</p>
<p>To design occlusion, use a lowpass filter on the source, either as <code>filter</code> or
<code>filter_direct</code>.  Synthizer doesn't currently provide anything to help because
it's not possible to build a proper physics-based occlusion model and it is
sometimes even beneficial to use bandpass or highpass filters instead (e.g.
haudio traveling through a pipe). It has to be done per application.</p>
<h1 id="the-synthizer-c-api"><a class="header" href="#the-synthizer-c-api">The Synthizer C API</a></h1>
<p>Synthizer has the following headers:</p>
<ul>
<li><code>synthizer.h</code>: All library functions</li>
<li><code>synthizer_constants.h</code>: Constants, i.e. the very large property enum.</li>
</ul>
<p>These headers are separated because it is easier in some cases to machine parse
<code>synthizer_constants.h</code> when writing bindings for languages which don't have
good automatic generation, then manually handle <code>synthizer.h</code>.</p>
<p>The Synthizer C API returns errors and writes results to out parameters.  Out
parameters are always the first parameters of a function, and errors are always
nonzero.  Note that error codes are currently not defined; they will be, once
things are more stable.</p>
<p>It is possible to get information on the last error using these functions:</p>
<pre><code>SYZ_CAPI syz_ErrorCode syz_getLastErrorCode(void);
SYZ_CAPI const char *syz_getLastErrorMessage(void);
</code></pre>
<p>These are thread-local functions.  The last error message is valid until the
next call into Synthizer.</p>
<h1 id="logging-initialization-and-shutdown"><a class="header" href="#logging-initialization-and-shutdown">Logging, Initialization, and Shutdown</a></h1>
<p>The following excerpts from <code>synthizer.h</code> specify the loggin and initialization
API. Explanation follows:</p>
<pre><code>enum SYZ_LOGGING_BACKEND {
    SYZ_LOGGING_BACKEND_NONE,
    SYZ_LOGGING_BACKEND_STDERR,
};

enum SYZ_LOG_LEVEL {
    SYZ_LOG_LEVEL_ERROR = 0,
    SYZ_LOG_LEVEL_WARN = 10,
    SYZ_LOG_LEVEL_INFO = 20,
    SYZ_LOG_LEVEL_DEBUG = 30,
};

struct syz_LibraryConfig {
    unsigned int log_level;
    unsigned int logging_backend;
    const char *libsndfile_path;
};

SYZ_CAPI void syz_libraryConfigSetDefaults(struct syz_LibraryConfig *config);

SYZ_CAPI syz_ErrorCode syz_initialize(void);    
SYZ_CAPI syz_ErrorCode syz_initializeWithConfig(const struct syz_LibraryConfig *config);
SYZ_CAPI syz_ErrorCode syz_shutdown();
</code></pre>
<p>Synthizer can be initialized in two ways.  The simplest is <code>syz_initialize</code>
which will use reasonable library defaults for most apps.  The second is
(excluding error checking):</p>
<pre><code>struct syz_LibraryConfig cfg;

syz_libraryConfigSetDefaults(&amp;config)l;
syz_initializeWithConfig(&amp;config);
</code></pre>
<p>In particular, the latter approach allows for enabling logging and loading
Libsndfile.</p>
<p>Currently Synthizer can only log to stderr and logging is slow enough that it
shouldn't be enabled in production.  It mostly exists for debugging.  In future
these restrictions will be lifted.</p>
<p>For more information on Libsndfile support, see <a href="concepts/./libsndfile.html">the dedicated
chapter</a>.</p>
<h1 id="handles-and-userdata"><a class="header" href="#handles-and-userdata">Handles and userdata</a></h1>
<p>Synthizer objects are referred to via reference-counted handles, with an
optional <code>void *</code> userdata pointer that can be associated to link them to
application state:</p>
<pre><code>SYZ_CAPI syz_ErrorCode syz_handleIncRef(syz_Handle handle);
SYZ_CAPI syz_ErrorCode syz_handleDecRef(syz_Handle handle);
SYZ_CAPI syz_ErrorCode syz_handleGetObjectType(int *out, syz_Handle handle);

SYZ_CAPI syz_ErrorCode syz_handleGetUserdata(void **out, syz_Handle handle);
typedef void syz_UserdataFreeCallback(void *);
SYZ_CAPI syz_ErrorCode syz_handleSetUserdata(syz_Handle handle, void *userdata, syz_UserdataFreeCallback *free_callback);
</code></pre>
<h2 id="basics-of-handles"><a class="header" href="#basics-of-handles">basics of Handles</a></h2>
<p>All Synthizer handles start with a reference count of 1.  When the reference
count reaches 0, the object is scheduled for deletion, but may not be deleted
immediately.  Uniquely among Synthizer functions, <code>syz_handleIncRef</code> and
<code>syz_handleDecRef</code> can be called after library shutdown in order to allow
languages like Rust to implement infallible cloning and freeing.  The issues
introduced with respect to object lifetimes due to the fact that Synthizer
objects may stay around for a while can be dealt with userdata support, as
described below.</p>
<p>Synthizer objects are like classes.  They have &quot;methods&quot; and &quot;bases&quot;.  For
example all generators support a common set of operations named with a
<code>syz_generatorXXX</code> prefix.</p>
<h3 id="userdata"><a class="header" href="#userdata">Userdata</a></h3>
<p>Synthizer makes it possible to associate application data via a <code>void *</code> pointer
which will share the object's actual lifetime rather than the lifetime of the
handle to the object.  This is useful for allowing applications to store state,
but also helps to deal with the lifetime issues introduced by the mismatch
between the last reference count of the object dying and the object actually
dying.  For example, the Rust and Python bindings use userdata to attach buffers
to objects when streaming from memory, so that the actual underlying resource
stays around until Synthizer is guaranteed to no longer use it.</p>
<p>Getting and setting userdata pointers is done in one of two ways.  All Synthizer
constructors take two additional parameters to set the userdata and the free
callback.  Alternatively, an application can go through <code>syz_getUserdata</code> and
<code>syz_setUserdata</code>.  These are a threadsafe interface which will associate a
<code>void *</code> argument with the object.  This interface acts as if the operations
were wrapped in a mutex internally, though they complete with no syscalls in all
reasonable cases of library usage.</p>
<p>The <code>free_callback</code> parameter to <code>syz_setUserdata</code> is optional.  If present, it
will be called on the userdata pointer when the object is destroyed or when a
new userdata pointer is set.  Due to limitations of efficient audio programming,
this free happens in a background thread and may occur up to hundreds of
milliseconds after the object no longer exists.</p>
<p>Most bindings will bind userdata support in a more friendly way.  For example,
Python provides a <code>get_userdata</code> and <code>set_userdata</code> pair which work on normal
Python objects.</p>
<h1 id="basics-of-audio-in-synthizer"><a class="header" href="#basics-of-audio-in-synthizer">basics of Audio in Synthizer</a></h1>
<p>This section explains how to get audio into and out of Synthizer.  The following
objects must be used by every application:</p>
<ul>
<li>Generators produce audio, for example by reading a buffer of audio data.</li>
<li>Sources play audio from one or more generators.</li>
<li>Contexts represent audio devices and group objects for the same device
together.</li>
</ul>
<p>The most basic flow of Synthizer is to create a context, source, and generator,
then connect the generator to the source.  For example, you might combine
<a href="concepts/../object_reference/buffer_generator.html">BufferGenerator</a> and
<a href="concepts/../object_reference/direct_source.html">DirectSource</a> to play a stereo audio file
to the speakers, or swap <code>DirectSource</code> for
<a href="concepts/../object_reference/source_3d.html">Source3D</a> to place the sound in the 3D
environment.</p>
<h1 id="the-context-1"><a class="header" href="#the-context-1">The Context</a></h1>
<p><a href="concepts/../object_reference/context.html">Contexts</a> represent audio devices and the
listener in 3D space.  They:</p>
<ul>
<li>Figure out the output channel format necessary for the current audio device
and convert audio to it.</li>
<li>Offer the ability to globally set gain.</li>
<li>Let users set the position of the listener in 3D space.</li>
<li>Let users set defaults for other objects, primarily the distance model and
panning strategies.
<ul>
<li>If your application wants HRTF on by default, it is done on the context by
setting <code>SYZ_P_PANNER_STRATEGY</code>.</li>
</ul>
</li>
</ul>
<p>For more information on 3D audio, see <a href="concepts/./3d_audio.html">the dedicated section</a>.</p>
<p>Almost all objects in Synthizer requirea  context to be created and must be used
only with the context they're associated with.</p>
<p>A common question is whether an app should ever have more than one context.
Though this is possible, contexts are very expensive objects that directly
correspond to audio devices.  Having 2 or 3 is the upper limit of what is
reasonable, but it is by far easiest to only have one as this prevents running
into issues where you mix objects from different contexts together.</p>
<h1 id="introduction-to-generators"><a class="header" href="#introduction-to-generators">Introduction to Generators</a></h1>
<p>generators are how audio first enters Synthizer.  They can do things like <a href="concepts/../object_reference/buffer_generator.html">play
a buffer</a>, <a href="concepts/../object_reference/noise_generator.html">generate
noise</a>, or <a href="concepts/../object_reference/streaming_generator.html">stream audio
data</a>.  By themselves, they're
silent and don't do anything, so they must be <a href="concepts/./sources.html">connected to
sources</a> via <code>syz_sourceAddGenerator</code>.</p>
<p>Generators are like a stereo without speakers: you have to plug them into
something else before they're audible.  In this case the &quot;something else&quot; is a
source.  Synthizer only supports using a generator with one source at a time,
but every source can have multiple generators.  That is, given generators <code>g1</code>
and <code>g2</code> and sources <code>s1</code> and <code>s2</code>, then <code>g1</code> and <code>g2</code> could be conneccted to
<code>s1</code>, <code>g1</code> to <code>s1</code> and <code>g2</code> to <code>s2</code>, but not <code>g1</code> to both <code>s1</code> and <code>s2</code> at the
same time.</p>
<h1 id="introduction-to-sources"><a class="header" href="#introduction-to-sources">Introduction to Sources</a></h1>
<p>Sources are how generators are made audible.  Synthizer offers 3 main kinds of
source:</p>
<ul>
<li>The <a href="concepts/../object_reference/direct_source.html">DirectSource</a> plays audio directly,
and can be used for things like background music.  This is the only source
type which won't convert audio to mono before using it.</li>
<li>The <a href="concepts/../object_reference/panned_source.html">PannedSource</a> allows for manual
control over pan, either by azimuth/elevation or via a scalar from -1 to 1
where -1 is all left and 1 is all right.</li>
<li>The <a href="concepts/../object_reference/source_3d.html">Source3D</a> allows for positioning audio
in 3D space.</li>
</ul>
<p>Every source offers the following functions:</p>
<pre><code>SYZ_CAPI syz_ErrorCode syz_sourceAddGenerator(syz_Handle source, syz_Handle generator);
SYZ_CAPI syz_ErrorCode syz_sourceRemoveGenerator(syz_Handle source, syz_Handle generator);
</code></pre>
<p>Every source will mix audio from as many generators as are connected to it and
then feed the audio through to the output of the source and to effects.  See the
section on <a href="concepts/./channel_mixing.html">channel mixing</a> for how audio is converted to
various different output formats, and <a href="concepts/./filters_and_effects.html">effects and
filters</a> for information on how to do more with this
API than simply playing audio.</p>
<h1 id="controlling-object-properties"><a class="header" href="#controlling-object-properties">Controlling Object Properties</a></h1>
<h2 id="basics"><a class="header" href="#basics">Basics</a></h2>
<p>most interesting audio control happens through properties, which are like knobs
on hardware controllers or dials in your DAW.  Synthizer picks the values of
properties up on the next audio tick and automatically handles crossfading and
graceful changes as your app drives the values.  Every property is identified
with a <code>SYZ_P</code> constant in <code>synthizer_constants.h</code>.  IN bindings,
<code>SYZ_P_MY_PROPERTY</code> will generally become <code>my_property</code> or <code>MyProperty</code> or etc.
depending on the dominant style of the language, and then either become an
actual settable property or a <code>get_property</code> and <code>set_property</code> pair depending
on if the language in question supports customized properties that aren't just
member variables (e.g. <code>@property</code> in Python, properties in C#).</p>
<p>All properties are of one of the following types:</p>
<ul>
<li><code>int</code> or <code>double</code>, identified by a <code>i</code> and <code>d</code> suffix in the property API, the
standard C primitive types.</li>
<li><code>double3</code> and <code>double6</code>, identified by <code>d3</code> and <code>d6</code> suffixes, vectors of 3
doubles and 6 doubles respectively.  Primarily used to set position and
orientation.</li>
<li><code>object</code>, identified by a <code>o</code> suffix, used to set object properties such as
the buffer to use for a buffer generator.</li>
<li><code>biquad</code>, configuration for a biquad filter.  Used on effects and sources to
allow filtering audio.</li>
</ul>
<p>No property constant represents a property of two types.  For example
<code>SYZ_P_POSITION</code> is both on <code>Context</code> and <code>Source3D</code> but is a <code>d3</code> in both
cases.  Generators use <code>SYZ_P_PLAYBACK_POSITION</code>, which is always a double.
Synthizer will always maintain this constraint.</p>
<p>The Property API is as follows:</p>
<pre><code>SYZ_CAPI syz_ErrorCode syz_getI(int *out, syz_Handle target, int property);
SYZ_CAPI syz_ErrorCode syz_setI(syz_Handle target, int property, int value);

SYZ_CAPI syz_ErrorCode syz_getD(double *out, syz_Handle target, int property);
SYZ_CAPI syz_ErrorCode syz_setD(syz_Handle target, int property, double value);

SYZ_CAPI syz_ErrorCode syz_setO(syz_Handle target, int property, syz_Handle value);

SYZ_CAPI syz_ErrorCode syz_getD3(double *x, double *y, double *z, syz_Handle target, int property);
SYZ_CAPI syz_ErrorCode syz_setD3(syz_Handle target, int property, double x, double y, double z);

SYZ_CAPI syz_ErrorCode syz_getD6(double *x1, double *y1, double *z1, double *x2, double *y2, double *z2, syz_Handle target, int property);
SYZ_CAPI syz_ErrorCode syz_setD6(syz_Handle handle, int property, double x1, double y1, double z1, double x2, double y2, double z2);

SYZ_CAPI syz_ErrorCode syz_getBiquad(struct syz_BiquadConfig *filter, syz_Handle target, int property);
SYZ_CAPI syz_ErrorCode syz_setBiquad(syz_Handle target, int property, const struct syz_BiquadConfig *filter);
</code></pre>
<p>Property accesses happen without syscalls and are usually atomic operations and
enqueues on a lockfree queue.</p>
<h2 id="object-properties-are-weak"><a class="header" href="#object-properties-are-weak">Object Properties Are Weak</a></h2>
<p>Object properties do not increment the reference count of the handle associated
with them.  There isn't much to say here, but it is important enough that it's
worth calling out with a section.  For example, if you set the buffer on a
buffer generator and then decrement the buffer's reference count to 0, the
generator will stop playing audio rather than keeping the buffer alive.</p>
<h2 id="a-note-on-reading"><a class="header" href="#a-note-on-reading">A Note on Reading</a></h2>
<p>Property reads need to be further explained.  Because audio programming requires
not blocking the audio thread, Synthizer internally uses queues for property
writes.  This means that any read may be outdated by some amount, even if the
thread making the read just set the value.  Typically, reads should be reserved
for properties that Synthizer also sets (e.g. <code>SYZ_P_PLAYBAKCK_POSITION</code>) or
used for debugging purposes.</p>
<p><code>syz_getO</code> is not offered by this API because it requires a mutex, which the
audio thread also can't handle.  Additionally, object lifetime concerns make it
more difficult for such an interface to do something sane.</p>
<p>Though the above limitations prevent this anyway, it is in general an
antipattern to store application state in your audio library.  Even if reads
were always up to date, it would still be slow to get data back out.
Applications should keep things like object position around and update
Synthizer, rather than asking Synthizer what the last value was.</p>
<h1 id="setting-gainvolume"><a class="header" href="#setting-gainvolume">Setting Gain/volume</a></h1>
<h2 id="syz_p_gain"><a class="header" href="#syz_p_gain"><code>SYZ_P_GAIN</code></a></h2>
<p>All objects which play audio (generators, sources, contexts) offer a
<code>SYZ_P_GAIN</code> property, a double scalar between 0.0 and infinity which controls
object volume.  For example <code>2.0</code> is twice the amplitude and <code>0.5</code> is half the
amplitude.  This works as you'd expect: if set on a generator it only affects
that generator, if on a source it affects everything connected to the source,
and so on.  If a generator is set to 0.5 and the source that it's on is also
0.5, the output volume of the generator is 0.25 because both gains apply in
order.</p>
<p>This means that it is possible to control the volume of generators relative to
each other when all connected to the same source, then control the overall
volume of the source.</p>
<h2 id="a-note-on-human-perception"><a class="header" href="#a-note-on-human-perception">A Note on Human Perception</a></h2>
<p>Humans don't perceive amplitude changes as you'd expect.  For example, moving
from 1.0 to 2.0 will generally sound like a large gap in volume, but from 2.0 to
3.0 much less so, and so on.  Most audio applications that expose volume sliders
to humans will expose them as decibels and convert to an amplitude factor
internally.  If you're just writing a game, you can mostly ignore this, but if
you're doing something more complicated a proper understanding of decibels is
important.  In decibals, a gain of 1.0 is at 0 dB and every increase and/or
decrease by 1 decibel sounds like the same amount of loudness as any other.  The
specific formulas to get to and/or from a gain are as follows:</p>
<pre><code>decibels = 20 * log10(gain)
gain = 10**(db/20)
</code></pre>
<p>Where <code>**</code> is exponentiation.</p>
<p>The obvious question is of course &quot;why not expose this as decibels?&quot;  The
problem with decibels is that gains over 1.0 will clip in most applications. But
a gain of 1.0 in decibels is 0 dB.  If there are two incredibly loud sounds both
with a gain of 1.0 playing at the same time, the overall gain is effectively
2.0, which can clip in the same way.  But 0 dB + 0 dB is still 0 dB even though
the correct gain is 2.0.  This gets worse for gains below 0.  Consider 0.5,
which is equivalent to roughly -6 dB.  0.5 + 0.5 is 1, but -6 + -6 is -12 dB.
Which isn't only wrong, it even moved in the wrong direction all together.</p>
<p>As a consequence Synthizer always uses multiplicative factors on the amplitude,
not decibels.  Unless you know what you're doing, you should convert to gain as
soon as possible and reason about how this works as a multiplier.</p>
<h1 id="pausing-and-resuming-playback"><a class="header" href="#pausing-and-resuming-playback">Pausing and Resuming Playback</a></h1>
<p>All objects which play audio offer the following two functions:</p>
<pre><code>SYZ_CAPI syz_ErrorCode syz_pause(syz_Handle object);
SYZ_CAPI syz_ErrorCode syz_play(syz_Handle object);
</code></pre>
<p>Which do exactly what they seem like they do.</p>
<p>In bindings, these are usually bound as instance methods, e.g. <code>myobj.pause()</code>.</p>
<h1 id="configuring-objects-to-continue-playing-until-silent"><a class="header" href="#configuring-objects-to-continue-playing-until-silent">Configuring Objects to Continue Playing Until Silent</a></h1>
<p>By default, Synthizer objects become silent when their reference counts go to 0,
but this isn't always what you want.  Sometimes, it is desirable to be able to
continue playing audio until the object is &quot;finished&quot;, for example for gunshots
or other one-off effects.  Synthizer calls this lingering, and offers the
following API to configure it:</p>
<pre><code>struct syz_DeleteBehaviorConfig {
    int linger;
    double linger_timeout;
};

SYZ_CAPI void syz_initDeleteBehaviorConfig(struct syz_DeleteBehaviorConfig *cfg);
SYZ_CAPI syz_ErrorCode syz_configDeleteBehavior(syz_Handle object, struct syz_DeleteBehaviorConfig *cfg);
</code></pre>
<p>To use it, call <code>syz_initDeleteBehaviorConfig</code> on an empty
<code>syz_DeleteBehaviorConfig</code> struct, fill out the struct, and call
<code>syz_configDeleteBehavior</code>.  The fields have the following meaning:</p>
<ul>
<li><code>linger</code>: if 0, die immediately, which is the default.  If 1, keep the object
around until it &quot;finishes&quot;.  What this means depends on the object and is
documented in the object reference, but it generally &quot;does what you'd expect&quot;.
For some examples:
<ul>
<li><code>BufferGenerator</code> will stop any looping and play until the end of the
buffer, or die immediately if paused.</li>
<li>All sources will keep going until all their generators are no longer around.</li>
</ul>
</li>
<li><code>linger_timeout</code>: if nonzero, set an upper bound on the amount of time an
object may linger for.  This is useful as a sanity check in your application.</li>
</ul>
<p>Lingering doesn't keep related objects alive.  For example a <code>BufferGenerator</code>
that is lingering still goes silent if the buffer attached to it is destroyed.</p>
<p>As with pausing, bindings usually make this an instance method.</p>
<h1 id="decoding-audio-data"><a class="header" href="#decoding-audio-data">Decoding Audio Data</a></h1>
<h2 id="the-quick-overview"><a class="header" href="#the-quick-overview">The Quick Overview</a></h2>
<p>Synthizer supports mp3, wav, and flac.  If you need more formats, then you can
<a href="concepts/./libsndfile.html">load Libsndfile</a> or decode the data yourself.</p>
<p>If you need to read from a file, use e.g. <code>syz_createBufferFromFile</code>.  If you
need to read from memory, use e.g. <code>syz_createBufferFromEncodedData</code>.  If you
need to just shove floats at Synthizer, use <code>syz_creatBufferFromFloatArray</code>.</p>
<p><a href="concepts/../object_reference/streaming_generator.html">StreamingGenerator</a> has a similar
set of methods.  In general you can find out what methods are available in the
object reference.  Everything supports some function that's equivalent to
<code>syz_createBufferFromFile</code>.</p>
<p>These functions are the most stable interface because they can be easily
supported across incompatible library versions.  If your app can use them, it
should do so.</p>
<h2 id="streams"><a class="header" href="#streams">Streams</a></h2>
<p>Almost all of these methods wrap and hide something called a stream handle,
which can be created with e.g. <code>syz_createStreamHandleFromFile</code>, then used with
e.g. <code>syz_createBufferFromStreamHandle</code>.  Bindings expose this to you, usually
with classes or your language's equivalent (e.g. in Python this is
<code>StreamHandle</code>).  This is used to get data from custom sources, for example the
network or encrypted asset stores.  For info on writing your own streams, see
<a href="concepts/./custom_streams.html">the dedicated section</a>.</p>
<p>In addition to get streams via specific methods, Synthizer also exposes a
generic interface:</p>
<pre><code>SYZ_CAPI syz_ErrorCode syz_createStreamHandleFromStreamParams(syz_Handle *out, const char *protocol, const char *path, void *param);
</code></pre>
<p>Using the generic interface, streams are referred to with:</p>
<ul>
<li>A protocol, for example<code>&quot;file&quot;</code>, which specifies the kind of stream it is.
Users can register their own protocols.</li>
<li>A path, for example to a file on disk.  This is protocol-specific.</li>
<li>And a <code>void *</code> param, which is passed through to the underlying stream
implementation, and currently ignored by Synthizer.</li>
</ul>
<p>So, for example, you might get a file by:</p>
<pre><code>syz_createStreamHandleFromStreamParams(&quot;file&quot;, path, NULL);
</code></pre>
<p>Streams don't support raw data.  They're always an encoded asset.  So for
example mp3 streams are a thing, but floats at 44100 streams aren't.  Synthizer
will offer a better interface for raw audio data pending there being enough
demand and a reason to go beyond <code>syz_createBufferFromFloatArray</code>.</p>
<h1 id="loading-libsndfile"><a class="header" href="#loading-libsndfile">Loading Libsndfile</a></h1>
<p>Synthizer supports 3 built-in audio formats: wav, MP3, and Flac.  For apps which
need more, Synthizer supports loading
<a href="http://www.mega-nerd.com/libsndfile/">Libsndfile</a>.  To do so, use
<code>syz_initializeWithConfig</code> and configure <code>libsndfile_path</code> to be the absolute
path to a Libsnddfile shared object (<code>.dll</code>, <code>.so</code>, etc).  Libsndfile will then
automatically be used where possible, replacing the built-in decoders.</p>
<p>Unfortunately, due to Libsndfile limitations, Libsndfile can only be used on
seekable streams of known length.  All Synthizer-provided methods of decoding
currently support this, but custom streams may opt not to do so, for example if
they're reading from the network.  In this case, Libsndfile will be skipped. To
see if this is happening, enable debug logging at library initialization and
Synthizer will log what decoders it's trying to use.</p>
<p>Because of licensing incompatibilities, Libsndfile cannot be statically linked
with Synthizer without effectively changing Synthizer's license to LGPL.
Consequently dynamic linking with explicit configuration is the only way to use
it.  Your app will need to arrange to distribute a Libsndfile binary as well and
use the procedure described above to load it.</p>
<h1 id="implementing-custom-streams-and-custom-stream-protocols"><a class="header" href="#implementing-custom-streams-and-custom-stream-protocols">Implementing Custom Streams and Custom Stream Protocols</a></h1>
<p>Synthizer supports implementing custom streams in order to read from places that
aren't files or memory: encrypted asset stores, the network, and so on.  This
section explains how to implement them.</p>
<p>before continuing, carefully consider whether you need this.  Implementing a
stream ina  higher level language and forcing Synthizer to go through it has a
small but likely noticeable performance hit.  It'll work fine, but the built-in
functionality will certainly be faster and more scalable.  Implementing a stream
in C is a complex process.  If your app can use the already-existing
funtionality, it is encouraged to do so.</p>
<h2 id="a-complete-python-example"><a class="header" href="#a-complete-python-example">A Complete Python Example</a></h2>
<p>The rest of this section will explain ind detail how streams work from the C
API, but this is a very complex topic and most of the infrastructure which
exists for it exists to make it possible to write convenient bindings.
Consequently, here is a complete and simple custom stream which wraps a Python
file object, registered as a custom protocol:</p>
<pre><code>class CustomStream:
    def __init__(self, path):
        self.file = open(path, &quot;rb&quot;)

    def read(self, size):
        return self.file.read(size)

    def seek(self, position):
        self.file.seek(position)

    def close(self):
        self.file.close()

    def get_length(self):
        pos = self.file.tell()
        len = self.file.seek(0, 2)
        self.file.seek(pos)
        return len

def factory(protocol, path, param):
    return CustomStream(path)


synthizer.register_stream_protocol(&quot;custom&quot;, factory)
gen = synthizer.StreamingGenerator.from_stream_params(ctx, &quot;custom&quot;, sys.argv[1])
</code></pre>
<p>Your bindings will document how to do this, for example in Python see
<code>help(synthizer.register_stream_protocol)</code>.  it's usually going to be this level
of complexity when doing it from a binding.  The rest of this section explains
what's going on from the C perspective, but non-C users are still encouriaged to
read it because it explains the general idea and offers best practices for
efficient and stable stream usage.</p>
<p>It's important to note that though this example demonstrates using
<code>StreamingGenerator</code>, buffers have similar methods to decode themselves from
streams.  Since <code>StreamingGenerator</code> has a large latency for anything but the
initial start-up, the primary use case is actually likely to be buffers.</p>
<h2 id="the-c-interface"><a class="header" href="#the-c-interface">The C Interface</a></h2>
<p>To define a custom stream, the following types are used:</p>
<pre><code>typedef int syz_StreamReadCallback(unsigned long long *read, unsigned long long requested, char *destination, void *userdata, const char ** err_msg);
typedef int syz_StreamSeekCallback(unsigned long long pos, void *userdata, const char **err_msg);
typedef int syz_StreamCloseCallback(void *userdata, const char **err_msg);
typedef void syz_StreamDestroyCallback(void *userdata);

struct syz_CustomStreamDef {
    syz_StreamReadCallback *read_cb;
    syz_StreamSeekCallback *seek_cb;
    syz_StreamCloseCallback *close_cb;
    syz_StreamDestroyCallback *destroy_cb;
    long long length;
    void *userdata;
};

SYZ_CAPI syz_ErrorCode syz_createStreamHandleFromCustomStream(syz_Handle *out, struct syz_CustomStreamDef *callbacks);

typedef int syz_StreamOpenCallback(struct syz_CustomStreamDef *callbacks, const char *protocol, const char *path, void *param, void *userdata, const char **err_msg);
SYZ_CAPI syz_ErrorCode syz_registerStreamProtocol(const char *protocol, syz_StreamOpenCallback *callback, void *userdata);
</code></pre>
<p>The following sections explain how these functions work.</p>
<h2 id="ways-to-get-a-custom-stream"><a class="header" href="#ways-to-get-a-custom-stream">Ways To Get A Custom Stream</a></h2>
<p>There are two ways to get a custom stream.  You can:</p>
<ul>
<li>Fill out the callbacks in <code>syz_CustomStreamDef</code> and use
<code>syz_createStreamHandleFromCustomStream</code>.</li>
<li>Write a function which will fill out <code>syz_CustomStreamDef</code> from the standard
stream parameters, and register a protocol with <code>syz_registerStreamProtocol</code>.</li>
</ul>
<p>The difference between these is the scope: if you don't register a protocol,
only your app can access the custom stream, presumably via a module that
produces them.  This is good because it keeps things modular.  If registering a
protocol, however, the protocol can be used from anywhere in the process,
including other libraries and modules.  For example, writing a
<code>encrypted_sqlite3</code> protocol C library could then be used to add the
<code>&quot;encrypted_sqlite3&quot;</code> protocol to any language.</p>
<p>Protocol names must be unique.  The behavior is undefined if they aren't.  A
good way of ensuring this is to namespace them.  For example,
<code>&quot;ahicks92.my_super_special_protocol&quot;</code>.</p>
<p>The <code>void *param</code> parameter is reserved for your implementation, and passed to
the factory callback if using the stream parameters approach.  It's assumed that
implementations going through <code>syz_createStreamHandleFromCustomStreamDef</code>
already have a way to move this information around.</p>
<h2 id="non-callback-syz_customstreamdef-parameters"><a class="header" href="#non-callback-syz_customstreamdef-parameters">Non-callback <code>syz_CustomStreamDef</code> parameters</a></h2>
<p>These are:</p>
<ul>
<li><code>length</code>, which must be set and known for seekable streams.  If the length of
the stream is unknown, set it to -1.</li>
<li><code>userdata</code>, which is passed as the userdata parameter to all stream callbacks.</li>
</ul>
<h2 id="the-stream-callbacks"><a class="header" href="#the-stream-callbacks">The Stream Callbacks</a></h2>
<p>Streams have the following callbacks, with mostly self-explanatory parameters:</p>
<ul>
<li>If going through the protocol interface, the open callback is called when the
stream is first opened.  If going through
<code>syz_createStreamHandleFromCustomStream</code>, it is assumed that the app already
opened the stream and has put whatever it is going to need into the <code>userdata</code>
field.</li>
<li>After that, the read and (if present) seek callbacks are called until the
stream is no longer needed.  The seek callback is optional.</li>
<li>The close callback is called when Synthizer will no longer use the underlying
asset.</li>
<li>The destroy callback, optional, is called when it is safe to free all
resources the stream is using.</li>
</ul>
<p>For more information on why we offer both the close and destroy callback, see
below on error handling.</p>
<p>All callbacks should return 0 on success, and (if necessary) write to their out
parameters.</p>
<p>The read callback must always read exactly as many bytes are requested, never
more.  If it reads less bytes than were requested, Synthizer treats this as an
end-of-stream condition.  If the end of the stream has already been reached, the
read callback should claim it read no bytes.</p>
<p>The seek callback is optional.  Streams don't need to support seeking, but (1)
this disables seeking in <code>StreamingGenerator</code> and (2) this disables support for
Libsndfile if Libsndfile was loaded.  In order to be seekable, a stream must:</p>
<ul>
<li>Have a seek callback; and</li>
<li>Fill out the <code>length</code> field with a positive value, the length of the stream in
bytes.</li>
</ul>
<h2 id="error-handling"><a class="header" href="#error-handling">Error Handling</a></h2>
<p>To indicate an error, callbacks should return a non-zero return value and
(optionally) set their <code>err_msg</code> parameter to a string representation of the
error.  Synthizer will log these errors if logging is enabled.  For more complex
error handling, apps are encouraged to ferry the information from streams to
their main threads themselves.  If a stream callback fails, Synthizer will
generally stop the stream all together.  Consequently, apps should do their best
to recover and never fail the stream.  Synthizer takes the approach of assuming
that any error is likely unrecoverable and expects that implementations already
did their best to succeed.</p>
<p>if the read callback fails, the position of the stream isn't updated.  If the
seek callback fails, Synthizer assumes that the position didn't move.</p>
<p>the reason that Synthizer offers a destroy callback in addition to one for
closing is so that streams may use non-static strings as error messages.
Synthizer may not be done logging these when the stream is closed, so apps doing
this should make sure that they live at least as long as the destroy callback,
after which Synthizer promises to never use anything related to this stream
again.</p>
<p>The simplest way to handle error messages for C users is to just use string
constants, but for other languages such as Python it is useful to be able to
convert errors to strings and attach them to the binding's object so that these
can be logged.  The destroy callback primarily exists for this use case.</p>
<p>Synthizer makes one more guarantee on the lifetime required of <code>err_msg</code>
strings: they need only live as long as the next time a stream callback is
called.  This means that, for example, the Python binding only keeps the most
recent error string around and replaces it as necessary.</p>
<h2 id="thread-safety"><a class="header" href="#thread-safety">Thread Safety</a></h2>
<p>Streams will only ever be used by one thread at a time, but may be moved between
threads.</p>
<h1 id="channel-upmixing-and-downmixing"><a class="header" href="#channel-upmixing-and-downmixing">Channel Upmixing and Downmixing</a></h1>
<p>Synthizer has built-in understanding of mono (1 channel) and stereo (2 channels)
audio formats.  It will mix other formats to these as necessary.  Specifically,
we:</p>
<ul>
<li>If converting from mono to any other format, broadcast the mono channel to all
of those in the other format.</li>
<li>If going to mono, sum and normalize the channels in the other format.</li>
<li>Otherwise, either drop extra channels or fill extra channels with silence.</li>
</ul>
<p>Synthizer will be extended to support surround sound in future, which will give
it a proper understanding of 4, 6, and 8 channels.  Since Synthizer is aimed at
non-experimental home media applications, we assume that the channel count is
sufficient to know what the format is goping to be.  For example, there is no
real alternative to 5.1 audio in the home environment if the audio has 6
channels.  If you need more complex multichannel handling, you can pre-convert
your audio to something Synthizer understands.  Otherwise, other libraries may
be a better option.</p>
<h1 id="3d-audio-panning-and-hrtf"><a class="header" href="#3d-audio-panning-and-hrtf">3D Audio, Panning, and HRTF</a></h1>
<h2 id="introduction-3"><a class="header" href="#introduction-3">Introduction</a></h2>
<p>Synthizer supports panning audio through two interfaces.</p>
<p>First is <a href="concepts/../object_reference/panned_source.html">PannedSource</a>, which provides
simple azimuth/elevation controls and the ability to pan based off a scalar, a
value between -1 (all left) and 1 (all right).  In this case the user
application must compute these values itself.</p>
<p>The second way is to use <a href="concepts/../object_reference/source_3d.html">Source3D</a>, which
simulates a 3D environment when fed positional data.  This ection concerns
itself with proper use of <code>Source3D</code>, which is less straightforward for those
who haven't had prior exposure to these concepts.</p>
<h2 id="introduction-4"><a class="header" href="#introduction-4">Introduction</a></h2>
<p>There are two mandatorey steps to using <code>Source3D</code> as well as a few optional
ones.  The two mandatory steps are these:</p>
<ul>
<li>On the context, update <code>SYZ_P_POSITION</code> and <code>SYZ_P_ORIENTATION</code> with the
listener's position and orientation</li>
<li>On the source, update <code>SYZ_P_POSITION</code> with the source's position.</li>
</ul>
<p>And optionally:</p>
<ul>
<li>Configure the default distance model to control how rapidly sources become
quiet.</li>
<li>Emphasize that sources have become close to the listener with the focus boost.</li>
<li>Add effects (covered in <a href="concepts/./filters_and_effects.html">a dedicated section</a>).</li>
</ul>
<h2 id="dont-move-sources-through-the-head"><a class="header" href="#dont-move-sources-through-the-head">Don't Move Sources Through the Head</a></h2>
<p>People frequently pick up Synthizer, then try to move the source through the
center of the listener's head, then ask why it's weird and didn't work.  It is
important to realize that this is a physical simulation of reality, and that the
reason you can move the source through the listener's head in the first place is
that this isn't an easily detectable case.  If you aren't driving Synthizer in a
way connected to physical reality--for example if you are attempting to use <code>x</code>
as a way to pan sources from left to right and not linked to a position--then
you probably want <code>PannedSource</code> instead.</p>
<h2 id="setting-global-defaults"><a class="header" href="#setting-global-defaults">Setting Global Defaults</a></h2>
<p>In addition to controlling the listener, the context offers the ability to set
defaults for all values discussed below.  This is done through a set of
<code>SYZ_P_DEFAULT_*</code> properties which match the names of those on sources.  This is
of particular interest to those wishing to use HRTF, which is off by default.</p>
<h2 id="synthizers-coordinate-system-and-orientations"><a class="header" href="#synthizers-coordinate-system-and-orientations">Synthizer's Coordinate System and Orientations</a></h2>
<p>The short version for those who are familiar with libraries that need position
and orientation data: Synthizer uses a right-handed coordinate system and
configures orientation through <a href="concepts/./properties.html">double6 properties</a> so that it
is possible to atomically set all 6 values at once.  This is represented as a
packed at and up vector pair in the format <code>(at_x, at_y, at_z, up_x, up_y, up_z)</code> on the context under the <code>SYZ_P_ORIENTATION</code> property.  As with every
other library doing a similar thing, these are unit vectors.</p>
<p>The short version for those who want a 2D coordinate system where positive y is
north, positive x is east, and player orientations are represented as degrees
clockwise of north: use only x and y of <code>SYZ_P_POSITION</code>, and set
<code>SYZ_P_ORIENTATION</code> as follows:</p>
<pre><code>(sin(angle * PI / 180), cos(angle * PI / 180), 0, 0, 0, 1)
</code></pre>
<p>The longer version is as follows.</p>
<p>Listener positions are represented through 3 values: the position, the at
vector, and the up vector.  The position is self-explanatory.  The at vector
points in the direction the listener is looking at all times, and the up vector
points out the top of the listener's head, as if there were a pole up the spine.
By driving these 3 values, it is possible to represent any position and
orientation a listener might assume.</p>
<p>Synthizer uses a right-handed coordinate system, which means that if the at
vector is pointed at positive x and the up vector at positive y, positive z
moves sources to the right.  This is called a right-handed coordinate system
because of the right-hand rule: if you point your fingers along positive x and
curl them toward positive y, your finger points at positive z.  This isn't a
standard.  Every library that does something with object positions tends to
choose a different value.  If combining Synthizer with other non-2D components,
it may be necessary to convert between coordinate systems. Resources on how to
do this may easily be found through Google.</p>
<p>The at and up vectors must always be orthogonal, that is forming a right angle
with each other.  In order to facilitate this, Synthizer uses double6 properties
so that both values can and must be set at the same time.  If we didn't, then
there would be a brief period where one was set and the other wasn't, in which
case they would temporarily be invalid.  Synthizer doesn't try to validate that
these vectors are orthogonal and generally tries to do its best when they
aren't, but nonetheless behavior in this case is undefined.</p>
<p>Finally, the at and up vectors must be unit vectors: vectors of length 1.</p>
<h2 id="panning-strategies-and-hrtf"><a class="header" href="#panning-strategies-and-hrtf">Panning strategies and HRTF.</a></h2>
<p>The panning strategy specifies how sources are to be panned.  Synthizer supports
the following panning strategies:</p>
<table><thead><tr><th>Strategy</th><th>Channels</th><th>Description</th></tr></thead><tbody>
<tr><td>SYZ_PANNER_STRATEGY_HRTF</td><td>2</td><td>An HRTF implementation, intended for use via headphones.</td></tr>
<tr><td>SYZ_PANNER_STRATEGY_STEREO</td><td>2</td><td>A simple stereo panning strategy assuming speakers are at -90 and 90.</td></tr>
</tbody></table>
<p>When a  source is first created, it gets the panning strategy from
<code>SYZ_P_DEFAULT_PANNER_STRATEGY</code> on the context.  Applications wishing to change
the default should do so before creating sources.</p>
<p>By default Synthizer is configured to use a stereo panning strategy, which
simply pans between two speakers.  This is because stereo panning strategies
work on all devices from headphones to 5.1 surround sound systems, and it is not
possible for Synthizer to reliably determine if the user is using headphones or
not.  HRTF provides a much better experience for headphone users but must be
enabled by your application through setting the default panner strategy or doing
so on individual sources.</p>
<p>Since panning strategies are per source, it is possible to have sources using
different panning strategies.  This is useful for two reasons: HRTF is expensive
enough that you may wish to disable it if dealing with hundreds or thousands of
sources, and it is sometimes useful to let UI elements use a different panning
strategy.  An example of this latter case is an audio gauge which pans from left
to right.</p>
<h2 id="distance-models"><a class="header" href="#distance-models">Distance Models</a></h2>
<p>The distance model controls how quickly sources become quiet as they move away
from the listener.  This is controlled through the following properties:</p>
<ul>
<li><code>SYZ_P_DISTANCE_MODEL</code>: which of the distance model formulas to use.</li>
<li><code>SYZ_P_DISTANCE_MAX</code>: the maximum distance at which the source will be
audible.</li>
<li><code>SYZ_P_DISTANCE_REF</code>: if you assume your source is a sphere, what's the radius
of it?</li>
<li><code>SYZ_P_ROLLOFF</code>: with some formulas, how rapidly does the sound get quieter?
Generally, configuring this to a higher value makes the sound drop off more
immediately near the head, then have more subtle changes at further distances.</li>
</ul>
<p>It is not possible to provide generally applicable advice for what you should
set the distance model to.  A game using meters needs very different settings
than one using feet or light years.  Furthermore, these don't have concrete
physical correspondances.  Of the things Synthizer offers, this is possibly the
least physically motivated and the most artistic from a game design perspective.
In other words: play with different values and see what you like.</p>
<p>The concrete formulas for the distance models are as follows.  Let <code>d</code> be the
distance to the source, <code>d_ref</code> the reference distance, <code>d_max</code> the max
distance, <code>r</code> the roll-off factor. Then the gain of the source is computed as a
linear scalar using one of the following formulas:</p>
<table><thead><tr><th>Model</th><th>Formula</th></tr></thead><tbody>
<tr><td>SYZ_DISTANCE_MODEL_NONE</td><td><code>1.0</code></td></tr>
<tr><td>SYZ_DISTANCE_MODEL_LINEAR</td><td>1 - r * (clamp(d, d_ref, d_max) - d_ref) / (d_max - d_ref);</td></tr>
<tr><td>SYZ_DISTANCE_MODEL_EXPONENTIAL when <code>d_ref == 0.0</code></td><td>0.0</td></tr>
<tr><td>SYZ_DISTANCE_MODEL_EXPONENTIAL when <code>d_ref &gt; 0.0</code></td><td><code>(max(d_ref, d) / d_ref) ** -r</code></td></tr>
<tr><td>SYZ_DISTANCE_MODEL_INVERSE when <code>d_ref = 0.0</code></td><td><code>0.0</code></td></tr>
<tr><td>SYZ_DISTANCE_MODEL_INVERSE when <code>d_ref &gt; 0.0</code></td><td><code>d_ref / (d_ref + r * max(d, d_ref) - d_ref)</code></td></tr>
</tbody></table>
<h2 id="the-closeness-boost"><a class="header" href="#the-closeness-boost">The Closeness Boost</a></h2>
<p>Sometimes, it is desirable to make sources &quot;pop out&quot; of the background
environment.  For example, if the player approaches an object with which they
can interact, making it noticeably louder as the boundary is crossed can be
useful.  This is of primary interest to audiogame designers, a type of game for
the blind, as it can be used to emphasize features of the environment in
non-realistic but informative ways.</p>
<p>This is controlled through two properties:</p>
<ul>
<li><code>SYZ_P_CLOSENESS_BOOST</code>: a value in DB controlling how much louder to make the
sound.  Negative values are allowed.</li>
<li><code>SYZ_P_CLOSENESS_BOOST_DISTANCE</code>: when the source is closer than this
distance, begin applying the closeness boost.</li>
</ul>
<p>When the source is closer than the configured distance, the normal gain
computation still applies, but an additional factor, the number of DB in the
closeness boost, is added.  This means that it is still possible for players to
know if they are getting closer to the source.</p>
<p>The reason that the closeness boost is specified inDB  is that otherwise it
would require values greater than 1.0, and it is primarily going to be fed from
artists and map developers.  If we discover that this is a problem in future, it
will be patched in a major Synthizer version bump.</p>
<p>Note that closeness boost has not gotten a lot of use yet.  Though we are
unlikely to remove the interface, the internal algorithms backing it might
change.</p>
<h1 id="filters-and-effects"><a class="header" href="#filters-and-effects">Filters and Effects</a></h1>
<p>Synthizer supports filters and effects in order to add environmental audio and
do more than just playing sources in a vacuum.  These sections explain how this
works.</p>
<h1 id="filters"><a class="header" href="#filters">Filters</a></h1>
<p>Synthizer supports a filter property type, as well as filters on effect sends.
The API for this is as follows:</p>
<pre><code>struct syz_BiquadConfig {
...
};

SYZ_CAPI syz_ErrorCode syz_getBiquad(struct syz_BiquadConfig *filter, syz_Handle target, int property);
SYZ_CAPI syz_ErrorCode syz_setBiquad(syz_Handle target, int property, const struct syz_BiquadConfig *filter);

SYZ_CAPI syz_ErrorCode syz_biquadDesignIdentity(struct syz_BiquadConfig *filter);
SYZ_CAPI syz_ErrorCode syz_biquadDesignLowpass(struct syz_BiquadConfig *filter, double frequency, double q);
SYZ_CAPI syz_ErrorCode syz_biquadDesignHighpass(struct syz_BiquadConfig *filter, double frequency, double q);
SYZ_CAPI syz_ErrorCode syz_biquadDesignBandpass(struct syz_BiquadConfig *filter, double frequency, double bandwidth);
</code></pre>
<p>See <a href="concepts/./properties.html">properties</a> for how to set filter properties and
<a href="concepts/./effects.html">effects</a> for how to apply filters to effect sends.</p>
<p>The struct <code>syz_BiquadConfig</code> is an opaque struct whose fields are only exposed
to allow allocating them on the stack.  It represents configuration for a biquad
filter, designed using the <a href="concepts/../appendices/audio_eq_cookbook.html">Audio EQ
Cookbook</a>. It's initialized with one of the
above design functions.</p>
<p>A suggested default for <code>q</code> is <code>0.7071135624381276</code>, which gives Buttererworth
lowpass and highpass filters. For those not already familiar with biquad
filters, <code>q</code> controls resonance: higher values of <code>q</code> will cause the filter to
ring for some period of time.</p>
<p>All sources support filters, which may be installed in 3 places:</p>
<ul>
<li><code>SYZ_P_FILTER</code>: applies to all audio traveling through the source.</li>
<li><code>SYZ_P_FILTER_DIRECT</code>: applied after <code>SYZ_P_FILTER</code> to audio going directly to
the speakers/through panners.</li>
<li><code>SYZ_P_FILTER_EFFECTS</code>: Applied after <code>SYZ_P_FILTER</code> to audio going to
effects.</li>
</ul>
<p>This allows filtering the audio to effects separately, for example to cut high
frequencies out of reverb on a source-by-source basis.</p>
<p>Additionally, all effects support a <code>SYZ_P_FILTER_INPUT</code>, which applies to all
input audio to the effect.  So, you can either have:</p>
<pre><code>source filter -&gt; direct path filter -&gt; speakers
</code></pre>
<p>Or:</p>
<pre><code>source filter -&gt; effects filter outgoing from source -&gt; filter on effect send -&gt; input filter to effect -&gt; effect
</code></pre>
<p>In future, Synthizer will stabilize the <code>syz_BiquadConfig</code> struct and use it to
expose more options, e.g. automated filter modulation.</p>
<h1 id="effects-and-effect-routing"><a class="header" href="#effects-and-effect-routing">Effects and Effect Routing</a></h1>
<p>users of the Synthizer API can route any number of sources to any number of
global effects, for example <a href="concepts/../object_reference/global_echo.html">echo</a>.  This is
done through the following C API:</p>
<pre><code>struct syz_RouteConfig {
    double gain;
    double fade_time;
    syz_BiquadConfig filter;
};

SYZ_CAPI syz_ErrorCode syz_initRouteConfig(struct syz_RouteConfig *cfg);
SYZ_CAPI syz_ErrorCode syz_routingConfigRoute(syz_Handle context, syz_Handle output, syz_Handle input, struct syz_RouteConfig *config);
SYZ_CAPI syz_ErrorCode syz_routingRemoveRoute(syz_Handle context, syz_Handle output, syz_Handle input, double fade_out);
</code></pre>
<p>Routes are uniquely identified by the output object (Source3D, etc) and input
object (Echo, etc).  There is no route handle type, nor is it possible to form
duplicate routes.</p>
<p>In order to establish or update the parameters of a route, use
<code>syz_routingConfigRoute</code>.  This will form a route if there wasn't already one,
and update the parameters as necessary.</p>
<p>It is necessary to initialize <code>syz_RouteConfig</code> with <code>syz_initRouteConfig</code>
before using it, but this need only be done once.  After that, reusing the same
<code>syz_RouteConfig</code> for a route without reinitializing it is encouraged.</p>
<p>Gains are per route and apply after the gain of the source. For example, you
might feed 70% of a source's output to something (gain = 0.7).</p>
<p>Filters are also per route and apply after any filters on sources.  For example,
this can be used to change the filter on a per-reverb basis for a reverb zone
algorithm that feeds sources to more than one reverb at a time.</p>
<p>In order to remove a route, use <code>syz_routingRemoveRoute</code>.</p>
<p>Many effects involve feedback and/or other long-running audio as part of their
intended function. But while in development, it is often useful to reset an
effect.  Synthizer exposes a function for this purpose:</p>
<pre><code>SYZ_CAPI syz_ErrorCode syz_effectReset(syz_Handle effect);
</code></pre>
<p>Which will work on any effect (at most, it does nothing).  As with things like
property access this is slow, and it's also not going to sound good, but it can
do things like clear out the feedback paths of a reverb at the Python shell for
interactive experimentation purposes.</p>
<h1 id="events-1"><a class="header" href="#events-1">Events</a></h1>
<p>Synthizer supports receivin events.  Currently, this is limited to knowing when
buffer/streaming generators have looped and/or finished.  Note that the use case
of destroying objects only after they have stopped playing is better handled
with <a href="concepts/./lingering.html">lingering</a>.</p>
<p>The API for this is as follows:</p>
<pre><code>struct syz_Event {
    int type;
    syz_Handle source;
    syz_Handle context;
};

SYZ_CAPI syz_ErrorCode syz_contextEnableEvents(syz_Handle context);
SYZ_CAPI syz_ErrorCode syz_contextGetNextEvent(struct syz_Event *out, syz_Handle context, unsigned long long flags);

SYZ_CAPI void syz_eventDeinit(struct syz_Event *event);
</code></pre>
<p>To begin receivin events, an application should call <code>syz_contextEnableEvents</code>.
This cannot be undone.  After a call to <code>syz_contextEnableEvents</code>, events will
begin to fill the event queue and must be retrieved with
<code>syz_contextGetNextEvent</code>.  Failure to call <code>syz_contextGetNextEvent</code> will
slowly fill the event queue, so applications should be sure to incorporate this
into their main UI/game update loops.  After the application is done with an
event struct, it should then call <code>syz_eventDeinit</code> on the event structure;
failure to do so leaksh handles.</p>
<p>The <code>flags</code> argument of <code>syz_getNextEvent</code> is reserved and must be 0.</p>
<p>Events have a type, context, and source.  The type is the kind of the vent.  The
context is the context from which the event was extracted.  The source is the
source of the event.  Sources are not sources as in the Synthizer object, and
are actually most commonly generators.</p>
<p>Event type constants are declared in <code>synthizer_constants.h</code> with all other
constants.  Currently Synthizer only offers <code>SYZ_EVENT_TYPE_FINISHED</code> and
<code>SYZ_EVENT_TYPE_LOOPED</code> which do exactly what they sound like: finished fires
when a generator which isn't configured to loop finished, and looped every time
a looping generator resets.</p>
<p>A special event type constant, <code>SYZ_EVENT_TYPE_INVALID</code>, is returned by
<code>syz_contextGetNextEvent</code> when there are no events in the queue.  To write a
proper event loop (excluding error handling):</p>
<pre><code>struct syz_Event evt;

while(1) {
    syz_contextGetNextEvent(&amp;evt, context, 0);
    if (evt.type == SYZ_EVENT_TYPE_INVALID) {
        break;
    }
    // handle it
}
</code></pre>
<p>Synthizer will never return an event if any handle to which the event refers is
invalid at the time the event was extracted from the queue.  This allows
applications to delete handles without having to concern themselves with whether
or not an event refers to a deleted handle.</p>
<p>In order to also offer thread safety, Synthizer event handling will temporarily
increment the reference counts of any handles to which an event refers, then
decrement them when <code>syz_eventDeinit</code> is called.  This allows applications the
ability to delete objects on threads other than the thread handling the event,
at the cost of extending the lifetimes of these handles slightly.  It is
possible for an application to call <code>syz_handleIncRef</code> if the application wishes
to keep one of these handles around.</p>
<h1 id="stability-and-versioning"><a class="header" href="#stability-and-versioning">Stability and Versioning</a></h1>
<p>Synthizer uses pre-1.0 semantic versioning.  This means:</p>
<ul>
<li>Major is always 0.</li>
<li>Minor is incremented for incompatible API changes.</li>
<li>Patch is incremented for new features and/or bug fixes.</li>
</ul>
<p>Synthizer is intended to be production ready software, but has not seen wide
usage.  It's somewhere between beta and 1.0: not as many features as you might
want, but also not crashing at the drop of a hat. If you find bugs, please
report them <a href="https://github.com/synthizer/synthizer">against the official
repository</a>.</p>
<p>API breakage is still expected.  This manual attempts to document where API
breakage may occur.  These are referred to as provisional features.</p>
<h1 id="context"><a class="header" href="#context">Context</a></h1>
<h2 id="constructors"><a class="header" href="#constructors">Constructors</a></h2>
<h3 id="syz_createcontext"><a class="header" href="#syz_createcontext"><code>syz_createContext</code></a></h3>
<pre><code>SYZ_CAPI syz_ErrorCode syz_createContext(syz_Handle *out, void *userdata, syz_UserdataFreeCallback *userdata_free_callback);
</code></pre>
<p>Creates a context configured to play through the default output device.</p>
<h2 id="properties-1"><a class="header" href="#properties-1">Properties</a></h2>
<table><thead><tr><th>Enum</th><th>Type</th><th>Default</th><th>Range</th><th>Description</th></tr></thead><tbody>
<tr><td>SYZ_P_GAIN</td><td>double</td><td>1.0</td><td>value &gt;= 0.0</td><td>The gain of the context</td></tr>
<tr><td>SYZ_P_POSITION</td><td>double3</td><td>(0, 0, 0)</td><td>any</td><td>The position of the listener.</td></tr>
<tr><td>SYZ_P_ORIENTATION</td><td>double6</td><td>(0, 1, 0, 0, 0, 1)</td><td>Two packed unit vectors</td><td>The orientation of the listener as <code>(atx, aty, atz, upx, upy, upz)</code>.</td></tr>
<tr><td>SYZ_P_DEFAULT_DISTANCE_MODEL</td><td>int</td><td>SYZ_DISTANCE_MODEL_LINEAR</td><td>any SYZ_DISTANCE_MODEL</td><td>The default distance model for new sources.</td></tr>
<tr><td>SYZ_P_DEFAULT_DISTANCE_REF</td><td>double</td><td>1.0</td><td>value &gt;= 0.0</td><td>The default reference distance for new sources.</td></tr>
<tr><td>SYZ_P_DEFAULT_DISTANCE_MAX</td><td>double</td><td>50.0</td><td>value &gt;= 0.0</td><td>The default max distance for new sources.</td></tr>
<tr><td>SYZ_P_DEFAULT_ROLLOFF</td><td>double</td><td>1.0</td><td>value &gt;= 0.0</td><td>The default rolloff for new sources.</td></tr>
<tr><td>SYZ_P_DEFAULT_CLOSENESS_BOOST</td><td>double</td><td>0.0</td><td>any finite double</td><td>The default closeness boost for new sources in DB.</td></tr>
<tr><td>SYZ_P_DEFAULT_CLOSENESS_BOOST_DISTANCE</td><td>double</td><td>0.0</td><td>value &gt;= 0.0</td><td>The default closeness boost distance for new sources</td></tr>
<tr><td>SYZ_P_DEFAULT_PANNER_STRATEGY</td><td>int</td><td>SYZ_PANNER_STRATEGY_STEREO</td><td>any SYZ_PANNER_STRATEGY</td><td>The default panner strategy for new sources.</td></tr>
</tbody></table>
<h2 id="functions"><a class="header" href="#functions">Functions</a></h2>
<h3 id="syz_contextgetnextevent"><a class="header" href="#syz_contextgetnextevent"><code>syz_contextGetNextEvent</code></a></h3>
<p>See <a href="object_reference/../concepts/events.html">events</a>.</p>
<h2 id="linger-behavior"><a class="header" href="#linger-behavior">Linger Behavior</a></h2>
<p>None.</p>
<h2 id="remarks"><a class="header" href="#remarks">Remarks</a></h2>
<p>The context is the main entrypoint to Synthizer, responsible for the following:</p>
<ul>
<li>Control and manipulation of the audio device.</li>
<li>Driving the audio threads.</li>
<li>Owning all objects that play together.</li>
<li>Representing the listener in 3D space.</li>
</ul>
<p>All objects which are associated with a context take a context as part of all
their constructors.  Two objects which are both associated with different
contexts should never interact. For efficiency, whether two objects are from
different contexts is unvalidated, and the behavior of mixing them is undefined.</p>
<p>All objects associated with a context become useless once the context is
destroyed.  Calls to them will still work, but they can't be reassociated with a
different context and no audioble output will result.</p>
<p>Most programs create one context and destroy it at shutdown.</p>
<p>For the time being, all contexts output stereo audio, and it is not possible to
specify the output device. These restrictions will be lifted in future.</p>
<p>For information on the meaning of the distance model properties, see <a href="object_reference/../concepts/3d_audio.html">3D
Audio</a>.</p>
<h1 id="buffer"><a class="header" href="#buffer">Buffer</a></h1>
<h2 id="constructors-1"><a class="header" href="#constructors-1">Constructors</a></h2>
<h3 id="syz_createbufferfromfile"><a class="header" href="#syz_createbufferfromfile"><code>syz_createBufferFromFile</code></a></h3>
<pre><code>SYZ_CAPI syz_ErrorCode syz_createBufferFromFile(syz_Handle *out, const char *path, void *userdata, syz_UserdataFreeCallback *userdata_free_callback);
</code></pre>
<p>Create a buffer from a file using an UTF-8 encoded path.</p>
<h3 id="syz_createbufferfromstreamparams"><a class="header" href="#syz_createbufferfromstreamparams"><code>syz_createBufferFromStreamParams</code></a></h3>
<pre><code>SYZ_CAPI syz_ErrorCode syz_createBufferFromStreamParams(syz_Handle *out, const char *protocol, const char *path, void *param, void *userdata, syz_UserdataFreeCallback *userdata_free_callback);
</code></pre>
<p>Create a buffer from stream parameters.  See <a href="object_reference/../concepts/decoding.html">decoding</a>
for information on streams.</p>
<p>This call will decode the stream in the calling thread, returning errors as
necessary. Synthizer will eventually offer a BufferCache which supports
background decoding and caching, but for the moment the responsibility of
background decoding is placed on the calling program.</p>
<h3 id="syz_createbufferfromencodeddata"><a class="header" href="#syz_createbufferfromencodeddata"><code>syz_createBufferFromEncodedData</code></a></h3>
<pre><code>SYZ_CAPI syz_ErrorCode syz_createBufferFromEncodedData(syz_Handle *out, unsigned long long data_len, const char *data, void *userdata, syz_UserdataFreeCallback *userdata_free_callback);
</code></pre>
<p>Create a buffer from encoded audio data in ram, for example an ogg file read
from disk.  This will also work with mmapped pointers. As with all other
decoding, Synthizer will autodetect the type from the data. The pointer must
live for the duration of the call.</p>
<h3 id="syz_createbufferfromfloatarray"><a class="header" href="#syz_createbufferfromfloatarray"><code>syz_createBufferFromFloatArray</code></a></h3>
<pre><code>SYZ_CAPI syz_ErrorCode syz_createBufferFromFloatArray(syz_Handle *out, unsigned int sr, unsigned int channels, unsigned long long frames, const float *data, void *userdata, syz_UserdataFreeCallback *userdata_free_callback);
</code></pre>
<p>Create a buffer from an array of float data generated by the application.  The
array must be <code>channels * frames</code> elements.</p>
<h3 id="syz_createbufferfromstreamhandle"><a class="header" href="#syz_createbufferfromstreamhandle"><code>syz_createBufferFromStreamHandle</code></a></h3>
<pre><code>SYZ_CAPI syz_ErrorCode syz_createBufferFromStreamHandle(syz_Handle *out, syz_Handle stream, void *userdata, syz_UserdataFreeCallback *userdata_free_callback);
</code></pre>
<p>Create a buffer from a <a href="object_reference/../concepts/decoding.html">stream handle</a>.  Usually used
with custom streams.  Decodes in the calling thread.  The lifetime of the
stream's underlying asset need only be as long as this call.</p>
<h2 id="properties-2"><a class="header" href="#properties-2">Properties</a></h2>
<p>None.</p>
<h2 id="functions-1"><a class="header" href="#functions-1">Functions</a></h2>
<h3 id="getters"><a class="header" href="#getters">Getters</a></h3>
<pre><code>SYZ_CAPI syz_ErrorCode syz_bufferGetChannels(unsigned int *out, syz_Handle buffer);
SYZ_CAPI syz_ErrorCode syz_bufferGetLengthInSamples(unsigned int *out, syz_Handle buffer);
SYZ_CAPI syz_ErrorCode syz_bufferGetLengthInSeconds(double *out, syz_Handle buffer);
</code></pre>
<p>The self-explanatory getters. These aren't properties because they can't be
written and they shouldn't participate in the property infrastructure.</p>
<h2 id="remarks-1"><a class="header" href="#remarks-1">Remarks</a></h2>
<p>Buffers hold audio data, as a collection of contiguous chunks.  Data is
resampled to the Synthizer samplerate and converted to 16-bit PCM.</p>
<p>Buffers are one of the few Synthizer objects that don't require a context.  They
may be used freely with any object requiring a buffer, from any thread.  In
order to facilitate this, buffers are immutable after creation.</p>
<p>The approximate memory usage of a buffer in bytes is <code>2 * channels * duration_in_seconds * 44100</code>.  Loading large assets into buffers is not
recommended. For things such as music tracks, use
<a href="object_reference/./streaming_generator.html">StreamingGenerator</a>s.  Note that on 32-bit
architectures, some operating systems only allow a 2 gigabyte address space.
Synthizer avoids allocating buffers as contiguous arrays in part to allow
efficient use of 32-bit address spaces, but this only goes so far.  If on a
32-bit architecture, expect to run out of memory from Synthizer's perspective
well before decoding 2 Gigabytes of buffers simultaneously due to the inability
to find consecutive free pages.</p>
<h1 id="operations-common-to-all-sources"><a class="header" href="#operations-common-to-all-sources">Operations Common to All Sources</a></h1>
<h2 id="constructors-2"><a class="header" href="#constructors-2">Constructors</a></h2>
<p>None.</p>
<h2 id="properties-3"><a class="header" href="#properties-3">Properties</a></h2>
<table><thead><tr><th>Enum</th><th>Type</th><th>Default</th><th>Range</th><th>Description</th></tr></thead><tbody>
<tr><td>SYZ_P_GAIN</td><td>double</td><td>Any double &gt; 0</td><td>An additional gain factor applied to this source.</td><td></td></tr>
<tr><td>SYZ_P_FILTER</td><td>biquad</td><td>identity</td><td>any</td><td>A filter which applies to all audio leaving the source, before <code>SYZ_P_FILTER_DIRECT</code> and <code>SYZ_P_FILTER_EFFECTS</code>.</td></tr>
<tr><td>SYZ_P_FILTER_DIRECT</td><td>biquad</td><td>identity</td><td>any</td><td>A filter which applies after <code>SYZ_P_FILTER</code> but not to audio traveling to effect sends.</td></tr>
<tr><td>SYZ_P_FILTER_EFFECTS</td><td>biquad</td><td>identity</td><td>any</td><td>A filter which runs after <code>SYZ_P_FILTER</code> but only applies to audio traveling through effect sends.</td></tr>
</tbody></table>
<h2 id="functions-2"><a class="header" href="#functions-2">Functions</a></h2>
<h3 id="syz_sourceaddgenerator-syz_sourceremovegenerator"><a class="header" href="#syz_sourceaddgenerator-syz_sourceremovegenerator"><code>syz_sourceAddGenerator</code>, <code>syz_sourceRemoveGenerator</code></a></h3>
<pre><code>SYZ_CAPI syz_ErrorCode syz_sourceAddGenerator(syz_Handle source, syz_Handle generator);
SYZ_CAPI syz_ErrorCode syz_sourceRemoveGenerator(syz_Handle source, syz_Handle generator);
</code></pre>
<p>Add/remove a generator from a source. Each generator may be added once and
duplicate add calls will have no effect. Each generator should only be used with
one source at a time.</p>
<h2 id="remarks-2"><a class="header" href="#remarks-2">Remarks</a></h2>
<p>Sources represent audio output.  They combine all generators connected to them,
apply any effects if necessary, and feed the context. Subclasses of Source add
panning and other features.</p>
<p>All sources offer filters via <code>SYZ_P_FILTER</code>, <code>SYZ_P_FILTER_DIRECT</code> and
<code>SYZ_P_FILTER_EFFECTS</code>. First, <code>SYZ_P_FILTER</code> is applied, then the audio is
split into two paths: the portion heading directly to the speakers gets
<code>SYZ_P_FILTER_DIRECT</code>, and the portion heading to the effect sends gets
<code>SYZ_P_FILTER_EFFECTS</code>.  This can be used to simulate occlusion and perform
other per-source effect customization.</p>
<h1 id="directsource"><a class="header" href="#directsource">DirectSource</a></h1>
<h2 id="constructors-3"><a class="header" href="#constructors-3">Constructors</a></h2>
<h3 id="syz_createdirectsource"><a class="header" href="#syz_createdirectsource"><code>syz_createDirectSource</code></a></h3>
<pre><code>SYZ_CAPI syz_ErrorCode syz_createDirectSource(syz_Handle *out, syz_Handle context, void *userdata, syz_UserdataFreeCallback *userdata_free_callback);
</code></pre>
<p>Creates a direct source.</p>
<h2 id="properties-4"><a class="header" href="#properties-4">Properties</a></h2>
<p>Inherited from Source only.</p>
<h2 id="linger-behavior-1"><a class="header" href="#linger-behavior-1">Linger Behavior</a></h2>
<p>Lingers until the timeout or until all generators have been destroyed.</p>
<h2 id="remarks-3"><a class="header" href="#remarks-3">Remarks</a></h2>
<p>A direct source is for music and other audio assets that don't wish to
participate in panning, , and should be linked directly to speakers.</p>
<p>Audio is converted to the Context's channel count and passed directly through.</p>
<h1 id="operations-common-to-panned-and-3d-sources"><a class="header" href="#operations-common-to-panned-and-3d-sources">Operations Common to Panned and 3D Sources</a></h1>
<h2 id="constructors-4"><a class="header" href="#constructors-4">Constructors</a></h2>
<p>None</p>
<h2 id="properties-5"><a class="header" href="#properties-5">Properties</a></h2>
<table><thead><tr><th>Enum</th><th>Type</th><th>Default</th><th>Range</th><th>Description</th></tr></thead><tbody>
<tr><td>SYZ_P_PANNER_STRATEGY</td><td>int</td><td>delegated to Context</td><td>any SYZ_PANNER_STRATEGY</td><td>The panner strategy for this source.</td></tr>
</tbody></table>
<h2 id="remarks-4"><a class="header" href="#remarks-4">Remarks</a></h2>
<p>All panned sources allow setting their panner strategy, which is taken by
default from <code>SYZ_P_DEFAULT_PANNER_STRATEGY</code> on the context. See <a href="object_reference/../concepts/3d_audio.html">3D
Audio</a> for info on panner strategies.</p>
<h1 id="pannedsource"><a class="header" href="#pannedsource">PannedSource</a></h1>
<h2 id="constructors-5"><a class="header" href="#constructors-5">Constructors</a></h2>
<h3 id="syz_createpannedsource"><a class="header" href="#syz_createpannedsource"><code>syz_createPannedSource</code></a></h3>
<pre><code>SYZ_CAPI syz_ErrorCode syz_createPannedSource(syz_Handle *out, syz_Handle context, void *userdata, syz_UserdataFreeCallback *userdata_free_callback);
</code></pre>
<p>Creates a panned source.</p>
<h3 id="properties-6"><a class="header" href="#properties-6">Properties</a></h3>
<table><thead><tr><th>Enum</th><th>Type</th><th>Default</th><th>Range</th><th>Description</th></tr></thead><tbody>
<tr><td>SYZ_P_AZIMUTH</td><td>double</td><td>0.0</td><td>0.0 to 360.0</td><td>The azimuth of the panner. See remarks.</td></tr>
<tr><td>SYZ_P_ELEVATION</td><td>double</td><td>0.0</td><td>-90.0 to 90.0</td><td>See remarks</td></tr>
<tr><td>SYZ_P_PANNING_SCALAR</td><td>double</td><td>0.0</td><td>-1.0 to 1.0</td><td>see remarks</td></tr>
</tbody></table>
<h2 id="linger-behavior-2"><a class="header" href="#linger-behavior-2">Linger Behavior</a></h2>
<p>Lingers until all generators have been destroyed.</p>
<h2 id="remarks-5"><a class="header" href="#remarks-5">Remarks</a></h2>
<p>The PannedSource gives direct control over a panner, which is either controlled
via azimuth/elevation in degrees or a panning scalar.</p>
<p>If using azimuth/elevation, 0.0 azimuth is forward and positive angles are
clockwise.  Elevation ranges from -90 (down) to 90 (up).</p>
<p>Some applications want to control panners through a panning scalar instead, i.e.
for UI purposes. If using panning scalars, -1.0 is full left and 1.0 is full
right.</p>
<p>Applications should use either a panning scalar or azimuth/elevation, never both
on the same source.  Using both simultaneously is undefined behavior.</p>
<p>For information on panning, see <a href="object_reference/../concepts/3d_audio.html">3D Audio</a>.</p>
<h1 id="source3d"><a class="header" href="#source3d">Source3D</a></h1>
<h2 id="constructors-6"><a class="header" href="#constructors-6">Constructors</a></h2>
<h3 id="syz_createsource3d"><a class="header" href="#syz_createsource3d"><code>syz_createSource3D</code></a></h3>
<pre><code>SYZ_CAPI syz_ErrorCode syz_createSource3D(syz_Handle *out, syz_Handle context, void *userdata, syz_UserdataFreeCallback *userdata_free_callback);
</code></pre>
<p>Creates a source3d positioned at the origin and with no associated generators.</p>
<h2 id="properties-7"><a class="header" href="#properties-7">Properties</a></h2>
<table><thead><tr><th>Enum</th><th>Type</th><th>Default</th><th>Range</th><th>Description</th></tr></thead><tbody>
<tr><td>SYZ_P_POSITION</td><td>double3</td><td>(0, 0, 0)</td><td>any</td><td>The position of the source.</td></tr>
<tr><td>SYZ_P_ORIENTATION</td><td>double6</td><td>(0, 1, 0, 0, 0, 1)</td><td>Two packed unit vectors</td><td>The orientation of the source as <code>(atx, aty, atz, upx, upy, upz)</code>. Currently unused.</td></tr>
<tr><td>SYZ_P_DISTANCE_MODEL</td><td>int</td><td>from Context</td><td>any SYZ_DISTANCE_MODEL</td><td>The distance model for this source.</td></tr>
<tr><td>SYZ_P_DISTANCE_REF</td><td>double</td><td>From Context</td><td>value &gt;= 0.0</td><td>The reference distance.</td></tr>
<tr><td>SYZ_P_DISTANCE_MAX</td><td>double</td><td>From Context</td><td>value &gt;= 0.0</td><td>The max distance for this source.</td></tr>
<tr><td>SYZ_P_ROLLOFF</td><td>double</td><td>From Context</td><td>value &gt;= 0.0</td><td>The rolloff for this source.</td></tr>
<tr><td>SYZ_P_CLOSENESS_BOOST</td><td>double</td><td>From Context</td><td>any finite double</td><td>The closeness boost for this source in DB.</td></tr>
<tr><td>SYZ_P_CLOSENESS_BOOST_DISTANCE</td><td>double</td><td>From Context</td><td>value &gt;= 0.0</td><td>The closeness boost distance for this source.</td></tr>
</tbody></table>
<h2 id="linger-behavior-3"><a class="header" href="#linger-behavior-3">Linger Behavior</a></h2>
<p>Lingers until all generators are destroyed.</p>
<h2 id="remarks-6"><a class="header" href="#remarks-6">Remarks</a></h2>
<p>A Source3D represents an entity in 3D space.  For explanations of the above
properties, see <a href="object_reference/../concepts/3d_audio.html">3D Audio</a>.</p>
<p>When created, Source3D reads all of its defaults from the Context's
corresponding properties.  Changes to the Context versions don't affect already
created sources.  A typical use case is to configure the Context to the defaults
of the game, and then create sources.</p>
<h1 id="operations-common-to-all-generators"><a class="header" href="#operations-common-to-all-generators">Operations Common to All Generators</a></h1>
<p>Generators generate audio, and are how Synthizer knows what to play through
sources. </p>
<h2 id="properties-8"><a class="header" href="#properties-8">Properties</a></h2>
<p>All generators support the following properties:</p>
<table><thead><tr><th>Enum</th><th>Type</th><th>Default</th><th>Range</th><th>Description</th></tr></thead><tbody>
<tr><td>SYZ_P_GAIN</td><td>double</td><td>1.0</td><td>value &gt;= 0.0</td><td>The gain of the generator.</td></tr>
<tr><td>SYZ_P_PITCH_BEND</td><td>double</td><td>1.0</td><td>value &gt;= 0.0</td><td>Pitch bend of the generator as a multiplier (2.0 is +1 octave, 0.5 is -1 octave, etc)</td></tr>
</tbody></table>
<h2 id="remarks-7"><a class="header" href="#remarks-7">Remarks</a></h2>
<p>Not all generators support <code>SYZ_P_PITCH_BEND</code> because it doesn't necessarily
make sense for them to do so, but it can always be set.</p>
<h1 id="streaminggenerator"><a class="header" href="#streaminggenerator">StreamingGenerator</a></h1>
<h2 id="constructors-7"><a class="header" href="#constructors-7">Constructors</a></h2>
<h3 id="syz_createstreaminggeneratorfromfile"><a class="header" href="#syz_createstreaminggeneratorfromfile"><code>syz_createStreamingGeneratorFromFile</code></a></h3>
<pre><code>SYZ_CAPI syz_ErrorCode syz_createStreamingGeneratorFromFile(syz_Handle *out, syz_Handle context, const char *path, void *userdata, syz_UserdataFreeCallback *userdata_free_callback);
</code></pre>
<p>Create a StreamingGenerator from an UTF-8 encoded path.</p>
<h3 id="syz_createstreaminggeneratorfromstreamparams"><a class="header" href="#syz_createstreaminggeneratorfromstreamparams"><code>syz_createStreamingGeneratorFromStreamParams</code></a></h3>
<pre><code>SYZ_CAPI syz_ErrorCode syz_createStreamingGeneratorFromStreamParams(syz_Handle *out, syz_Handle context, const char *protocol, const char *path, void *param, void *userdata, syz_UserdataFreeCallback *userdata_free_callback);
</code></pre>
<p>Create a StreamingGenerator from the standard <a href="object_reference/../concepts/decoding.html">stream
parameters</a>.</p>
<h3 id="syz_createstreaminggeneratorfromstreamhandle"><a class="header" href="#syz_createstreaminggeneratorfromstreamhandle"><code>syz_createStreamingGeneratorFromStreamHandle</code></a></h3>
<pre><code>SYZ_CAPI syz_ErrorCode syz_createStreamingGeneratorFromStreamHandle(syz_Handle *out, syz_Handle context, syz_Handle stream, void *userdata, syz_UserdataFreeCallback *userdata_free_callback);
</code></pre>
<p>Create a <code>StreamingGenerator</code> from a stream handle.</p>
<h2 id="properties-9"><a class="header" href="#properties-9">Properties</a></h2>
<table><thead><tr><th>Enum</th><th>Type</th><th>Default Value</th><th>Range</th><th>Description</th></tr></thead><tbody>
<tr><td>SYZ_P_PLAYBACK_POSITION</td><td>double</td><td>0.0</td><td>value &gt;= 0.0</td><td>The position in of the stream.</td></tr>
<tr><td>SYZ_P_LOOPING</td><td>int</td><td>0</td><td>0 or 1</td><td>Whether playback loops</td></tr>
</tbody></table>
<h2 id="linger-behavior-4"><a class="header" href="#linger-behavior-4">Linger Behavior</a></h2>
<p>Disables looping and continues until the stream ends.</p>
<h2 id="remarks-8"><a class="header" href="#remarks-8">Remarks</a></h2>
<p><code>StreamingGenerator</code> plays streams, decoding and reading on demand.  The typical
use case is for music playback.</p>
<p>Due to the expense of streaming from disk and other I/O sources, having more
than a few StreamingGenerators going will cause a decrease in audio quality on
many systems, typically manifesting as drop-outs and crackling.
StreamingGenerator creates one background thread per instance and does all
decoding and I/O in that thread.</p>
<p>At startup, StreamingGenerator's background thread eagerly decodes a relatively
large amount of data in order to build up a buffer which prevents underruns.
Thereafter, it will pick up property changes every time the background thread
wakes up to add more data to the buffer.  This means that most operations are
high latency, currently on the order of 100 to 200 MS. The least latent
operation is the initial start-up, which will begin playing as soon as enough
data is decoded.  How long that takes depends on the format and I/O
characteristics of the stream, as well as the user's machine and current load of
the system.</p>
<h1 id="buffergenerator"><a class="header" href="#buffergenerator">BufferGenerator</a></h1>
<h2 id="constructors-8"><a class="header" href="#constructors-8">Constructors</a></h2>
<h3 id="syz_createbuffergenerator"><a class="header" href="#syz_createbuffergenerator"><code>syz_createBufferGenerator</code></a></h3>
<pre><code>SYZ_CAPI syz_ErrorCode syz_createBufferGenerator(syz_Handle *out, syz_Handle context, void *userdata, syz_UserdataFreeCallback *userdata_free_callback);
</code></pre>
<p>Creates a BufferGenerator. The buffer is set to NULL and the resulting generator
will play silence until one is associated.</p>
<h2 id="properties-10"><a class="header" href="#properties-10">Properties</a></h2>
<table><thead><tr><th>Enum</th><th>Type</th><th>Default Value</th><th>Range</th><th>Description</th></tr></thead><tbody>
<tr><td>SYZ_P_BUFFER</td><td>Object</td><td>0</td><td>Any Buffer handle</td><td>The buffer to play</td></tr>
<tr><td>SYZ_P_PLAYBACK_POSITION</td><td>double</td><td>0.0</td><td>value &gt;= 0.0</td><td>The position in the buffer.</td></tr>
<tr><td>SYZ_P_LOOPING</td><td>int</td><td>0</td><td>0 or 1</td><td>Whether playback loops at the end of the buffer.</td></tr>
</tbody></table>
<h2 id="linger-behavior-5"><a class="header" href="#linger-behavior-5">Linger behavior</a></h2>
<p>Disables looping and plays until the buffer ends.</p>
<h2 id="remarks-9"><a class="header" href="#remarks-9">Remarks</a></h2>
<p>BufferGenerators play <a href="object_reference/./buffer.html">Buffer</a>s.  This is the most efficient way to
play audio.</p>
<p><code>SYZ_P_PLAYBACK_POSITION</code> is reset if <code>SYZ_P_BUFFER</code> is modified.</p>
<p><code>SYZ_P_PLAYBACK_POSITION</code> can be set past the end of the buffer.  If
<code>SYZ_P_LOOPING = 0</code>, the generator will play silence.  Otherwise, the position
will immediately loop to the beginning.</p>
<p>More than one BufferGenerator can use the same underlying Buffer.</p>
<p>If the buffer being used by this generator is destroyed, this generator
immediately begins playing silence until another buffer is associated.</p>
<h1 id="noisegenerator"><a class="header" href="#noisegenerator">NoiseGenerator</a></h1>
<p>Inherits from <a href="object_reference/./generator.html">Generator</a>.</p>
<h2 id="constructors-9"><a class="header" href="#constructors-9">Constructors</a></h2>
<h3 id="syz_createnoisegenerator"><a class="header" href="#syz_createnoisegenerator"><code>syz_createNoiseGenerator</code></a></h3>
<pre><code>SYZ_CAPI syz_ErrorCode syz_createNoiseGenerator(syz_Handle *out, syz_Handle context, unsigned int channels, void *userdata, syz_UserdataFreeCallback *userdata_free_callback);
</code></pre>
<p>Creates a NoiseGenerator configured for uniform noise with the specified number
of output channels. The number of output channels cannot be configured at
runtime.  Each channel produces decorrelated noise.</p>
<h2 id="properties-11"><a class="header" href="#properties-11">Properties</a></h2>
<table><thead><tr><th>Enum</th><th>Type</th><th>Default Value</th><th>Range</th><th>Description</th></tr></thead><tbody>
<tr><td>SYZ_P_NOISE_TYPE</td><td>int</td><td>SYZ_NOISE_TYPE_UNIFORM</td><td>any SYZ_NOISE_TYPE</td><td>The type of noise to generate. See remarks.</td></tr>
</tbody></table>
<h2 id="linger-behavior-6"><a class="header" href="#linger-behavior-6">Linger Behavior</a></h2>
<p>Fades out over a few milliseconds.</p>
<h2 id="remarks-10"><a class="header" href="#remarks-10">Remarks</a></h2>
<p>NoiseGenerators generate noise.  This is most useful when filtered via the
source, and can make things such as plausible if low-quality wind and whistling
effects.</p>
<p>Synthizer allows setting the algorithm used to generate noise to one of the
following options.  Note that these are more precisely named than
white/pink/brown; the sections below document the equivalent in the more
standard nomenclature.</p>
<h3 id="syz_noise_type_uniform"><a class="header" href="#syz_noise_type_uniform"><code>SYZ_NOISE_TYPE_UNIFORM</code></a></h3>
<p>A uniform noise source.  From an audio perspective this is white noise, but is
sampled from a uniform rather than Gaussian distribution for efficiency.</p>
<h3 id="syz_noise_type_vm"><a class="header" href="#syz_noise_type_vm"><code>SYZ_NOISE_TYPE_VM</code></a></h3>
<p>This is pink noise generated with the Voss-McCartney algorithm, which consists
of a number of summed uniform random number generators which are run at
different rates. Synthizer adds an additional random number generator at the top
of the hierachy in order to improve the color of the noise in the high
frequencies.</p>
<h3 id="syz_noise_type_filtered_brown"><a class="header" href="#syz_noise_type_filtered_brown"><code>SYZ_NOISE_TYPE_FILTERED_BROWN</code></a></h3>
<p>This is brown noise generated with a -6DB filter.</p>
<h1 id="operations-common-to-all-effects"><a class="header" href="#operations-common-to-all-effects">Operations Common to All Effects</a></h1>
<h2 id="properties-12"><a class="header" href="#properties-12">Properties</a></h2>
<table><thead><tr><th>Enum</th><th>Type</th><th>Default</th><th>Range</th><th>Description</th></tr></thead><tbody>
<tr><td>SYZ_P_GAIN</td><td>double</td><td>usually 1.0</td><td>value &gt;= 0.0</td><td>The overall gain of the effect.</td></tr>
<tr><td>SYZ_P_FILTER_INPUT</td><td>biquad</td><td>usually identity. if not, documented with the effect.</td><td>any</td><td>A filter which applies to the input of this effect. Runs after filters on effect sends.</td></tr>
</tbody></table>
<h2 id="functions-3"><a class="header" href="#functions-3">Functions</a></h2>
<h3 id="syz_effectreset"><a class="header" href="#syz_effectreset"><code>syz_effectReset</code></a></h3>
<pre><code>SYZ_CAPI syz_ErrorCode syz_effectReset(syz_Handle effect);
</code></pre>
<p>Clears the internal state of the effect. Intended for design/development
purposes.  This function may produce clicks and other artifacts and is slow.</p>
<h2 id="remarks-11"><a class="header" href="#remarks-11">Remarks</a></h2>
<p>For more information on how effects work, see <a href="object_reference/../concepts/effects.html">the dedicated
section</a>.</p>
<h1 id="globalecho"><a class="header" href="#globalecho">GlobalEcho</a></h1>
<h2 id="constructors-10"><a class="header" href="#constructors-10">Constructors</a></h2>
<h3 id="syz_createglobalecho"><a class="header" href="#syz_createglobalecho"><code>syz_createGlobalEcho</code></a></h3>
<pre><code>SYZ_CAPI syz_ErrorCode syz_createGlobalEcho(syz_Handle *out, syz_Handle context, void *userdata, syz_UserdataFreeCallback *userdata_free_callback);
</code></pre>
<p>Creates an echoe effect.</p>
<h2 id="functions-4"><a class="header" href="#functions-4">Functions</a></h2>
<h3 id="syz_echosettaps"><a class="header" href="#syz_echosettaps"><code>syz_echoSetTaps</code></a></h3>
<pre><code>struct syz_EchoTapConfig {
    double delay;
    double gain_l;
    double gain_r;
};

SYZ_CAPI syz_ErrorCode syz_globalEchoSetTaps(syz_Handle handle, unsigned int n_taps, struct syz_EchoTapConfig *taps);
</code></pre>
<p>Configure the taps for this Echo.  Currently, delay must be no greater than 5
seconds.  To clear the taps, set the echo to an array of 0 elements.</p>
<h2 id="properties-13"><a class="header" href="#properties-13">Properties</a></h2>
<p>None</p>
<h2 id="linger-behavior-7"><a class="header" href="#linger-behavior-7">Linger Behavior</a></h2>
<p>Lingers until the delay line is empty, that is until no more echoes can possibly
be heard.</p>
<h2 id="remarks-12"><a class="header" href="#remarks-12">Remarks</a></h2>
<p>This is a stereo tapped delay line, with a one-block crossfade when taps are
reconfigured.  The max delay is currently fixed at 5 seconds, but this will be
made user configurable in future.</p>
<p>This implementation offers precise control over the placement of taps, at the
cost of not being able to have indefinitely long echo effects.  It's most useful
for modeling discrete, panned echo taps.  Some ways this is useful are:</p>
<ul>
<li>Emphasize footsteps off walls in large spaces, by computing the parameters for
the taps off level geometry.</li>
<li>Emphasize openings or cooridors.</li>
<li>Pair it with a reverb implementation to offer additional, highly controlled
early reflection emphasis</li>
</ul>
<p>This is effectively discrete convolution for 2 channels, implemented using an
algorithm designed for sparse taps. In other words, the cost of any echo effect
is <code>O(taps)</code> per sample.  Anything up to a few thousand discrete taps is
probably fine, but beyond that the cost will become prohibitive.</p>
<h1 id="globalfdnreverb"><a class="header" href="#globalfdnreverb">GlobalFdnReverb</a></h1>
<p>A reverb based off a feedback delay network.</p>
<p>Inherits from <a href="object_reference/./global_effect.html">GlobalEffect</a>.</p>
<h2 id="constructors-11"><a class="header" href="#constructors-11">Constructors</a></h2>
<h3 id="syz_createglobalfdnreverb"><a class="header" href="#syz_createglobalfdnreverb"><code>syz_createGlobalFdnReverb</code></a></h3>
<pre><code>SYZ_CAPI syz_ErrorCode syz_createGlobalFdnReverb(syz_Handle *out, syz_Handle context, void *userdata, syz_UserdataFreeCallback *userdata_free_callback);
</code></pre>
<p>Creates a global FDN reverb with default settings.</p>
<h2 id="properties-14"><a class="header" href="#properties-14">Properties</a></h2>
<p>See remarks for a description of what these do and how to use them effectively.</p>
<p>In addition to the below, FdnReverb defaults its gain to 0.7.  Gains of 1.0 are
almost never what you want, since that makes the reverb as loud as the
non-reverb audio paths.</p>
<table><thead><tr><th>Enum</th><th>Type</th><th>Default</th><th>Range</th><th>Description</th></tr></thead><tbody>
<tr><td>SYZ_P_INPUT_FILTER</td><td>Biquad</td><td>Lowpass Butterworth at 2000 HZ</td><td>any biquad</td><td>a filter that applies to the audio at the input of the reverb.</td></tr>
<tr><td>SYZ_P_MEAN_FREE_PATH</td><td>double</td><td>0.1</td><td>0.0 to 0.5</td><td>The mean free path of the simulated environment.</td></tr>
<tr><td>SYZ_P_T60</td><td>double</td><td>0.3</td><td>0.0 to 100.0</td><td>The T60 of the reverb</td></tr>
<tr><td>SYZ_P_LATE_REFLECTIONS_LF_ROLLOFF</td><td>double</td><td>1.0</td><td>0.0 to 2.0</td><td>A multiplicative factor on T60 for the low frequency band</td></tr>
<tr><td>SYZ_P_LATE_REFLECTIONS_LF_REFERENCE</td><td>double</td><td>200.0</td><td>0.0 to 22050.0</td><td>Where the low band of the feedback equalizer ends</td></tr>
<tr><td>SYZ_P_LATE_REFLECTIONS_HF_ROLLOFF</td><td>double</td><td>0.5</td><td>0.0 to 2.0</td><td>A multiplicative factor on T60 for the high frequency band</td></tr>
<tr><td>SYZ_P_LATE_REFLECTIONS_HF_REFERENCE</td><td>double</td><td>500.0</td><td>0.0 to 22050.0</td><td>Where the high band of the equalizer starts.</td></tr>
<tr><td>SYZ_P_LATE_REFLECTIONS_DIFFUSION</td><td>double</td><td>1.0</td><td>0.0 to 1.0</td><td>Controls the diffusion of the late reflections as a percent.</td></tr>
<tr><td>SYZ_P_LATE_REFLECTIONS_MODULATION_DEPTH</td><td>double</td><td>0.01</td><td>0.0 to 0.3</td><td>The depth of the modulation of the delay lines on the feedback path in seconds.</td></tr>
<tr><td>SYZ_P_LATE_REFLECTIONS_MODULATION_FREQUENCY</td><td>double</td><td>0.5</td><td>0.01 to 100.0</td><td>The frequency of the modulation of the delay lines inthe feedback paths.</td></tr>
<tr><td>SYZ_P_LATE_REFLECTIONS_DELAY</td><td>double</td><td>0.03</td><td>0.0 to 0.5</td><td>The delay of the late reflections relative to the input in seconds.</td></tr>
</tbody></table>
<h2 id="linger-behavior-8"><a class="header" href="#linger-behavior-8">Linger behavior</a></h2>
<p>Lingers for slightly longer than <code>t60</code>.</p>
<h2 id="remarks-13"><a class="header" href="#remarks-13">Remarks</a></h2>
<p>This is a reverb composed of a feedback delay network with 8 internal delay
lines.  The algorithm proceeds as follows:</p>
<ul>
<li>Audio is fed through the input filter, a lowpass.  Use this to eliminate high
frequencies, which can be quite harsh when fed to reverb algorithms.</li>
<li>Then, audio is fed into a series of 8 delay lines, connected with a feedback
matrix.  It's essentially a set of parallel allpass filters with some
additional feedbacks, but inspired by physics.
<ul>
<li>Each of these delay lines is modulated, to reduce periodicity.</li>
<li>On each feedback path, the audio is fed through an equalizer to precisely
control the decay rate in 3 frequency bands.</li>
</ul>
</li>
<li>Two decorrelated channels are extracted. This will be increased to 4 when
surround sound support is added.</li>
<li>Finally, the output is delayed by the late reflections delay.</li>
</ul>
<p>The current reverb modle is missing spatialized early reflections.  Practically
speaking this makes very little difference when using an FDN because the FDN
simulates them effectively on its own, but the <code>SYZ_P_EARLY_REFLECTIONS_*</code>
namespace is reserved for that purpose.  The plan is to feed them through HRTF
in order to attempt to capture the shape of the room, possibly with a per-source
model.</p>
<p>The reverb is also missing the ability to pan late reflections; this is on the
roadmap.</p>
<p>The default configuration is something to the effect of a medium-sized room.
Presets will be added in future.  The following sections explain considerations
for reverb design with this algorithm:</p>
<h3 id="a-note-on-property-changes"><a class="header" href="#a-note-on-property-changes">A Note On Property Changes</a></h3>
<p>The FdnReverb effect involves a large amount of feedback and is therefore
impossible to crossfade efficiently. To that end,we don't try.  Expect most
property changes save for t60 and the hf/lf frequency controls to cause clicking
and other artifacts.</p>
<p>To change properties smoothly, it's best to create a reverb, set all the
parameters, connect all the sources to the new one, and disconnect all the
sources from the old one, in that order.  Synthizer may eventually do this
internally, but that necessitates taking a permanent and large allocation cost
without a lot of implementation work being done first, so for the moment we
don't.</p>
<p>In practice, this doesn't matter.  Most environments don't change reverb
characteristics.  A good flow is as follows:</p>
<ul>
<li>Design the reverb in your level editor/other environment.</li>
<li>When necessary, use <code>syz_effectReset</code> for interactive experimentation.</li>
<li>When distributing/launching for real, use the above crossfading instructions.</li>
</ul>
<p>It is of course possible to use more than one reverb at a time as well, and to
fade sources between them at different levels. Note, however, that reverbs are
relatively expensive.</p>
<h3 id="the-input-filter"><a class="header" href="#the-input-filter">The Input Filter</a></h3>
<p>Most reverb algorithms have a problem: high frequencies are emphasized.
Synthizer's is no different.  To solve this, we introduce an input lowpass
filter, which can cut out the higher frequencies. This is <code>SYZ_P_FILTER_INPUT</code>,
available on all effects, but defaulted by the reverb to a lowpass at 1500 HZ
because most of the negative characteristics of reverbs occur when high
frequencies are overemphasized.</p>
<p>Changing this cutoff filter is the strongest tool available for coloring the
reverb.  Low cutoffs are great for rooms with sound dampening, high cutoffs for
concrete walls. It can be disabled, but doing so will typically cause metallic
and periodic artifacts to be noticeable.</p>
<p>It's also possible to swap it with other filter types.  Lowpass filters are
effectively the only filter type that aligns with the real world in the context
of a reverb, but other filter types can produce interesting effects.</p>
<h3 id="choosing-the-mean-free-path-and-late-reflections-delay"><a class="header" href="#choosing-the-mean-free-path-and-late-reflections-delay">Choosing the mean free path and late reflections delay</a></h3>
<p>These two values are most directly responsible for controlling how big a space
feels.  Intuitively, the mean free path is the average distance from wall to
wall, and the late reflections delay is the time it takes for audio to hit
something for the first time.  In general, get the mean free path by dividing
the average distance between the walls by the speed of sound, and set the late
reflections delay to something in the same order of magnitude.</p>
<p>A good approximation for the mean free path is <code>4 * volume / surface_area</code>.
Mathematically, it's the average time sound travels before reflection off an
obstacle.  Very large mean free paths produce many discrete echoes.  For
unrealistically large values, the late reflections won't be able to converge at
all.</p>
<h3 id="choosing-t60-and-controlling-per-band-decay"><a class="header" href="#choosing-t60-and-controlling-per-band-decay">Choosing T60 and controlling per-band decay</a></h3>
<p>The t60 and related properties control the gains and configuration of a filter
on the feedback path.</p>
<p>The t60 of a reverb is defined as the time it takes for the reverb to decay by
<code>-60db</code>.  Effectively this can be thought of as how long until the reverb is
completely silent. 0.2 to 0.5 is a particularly reverberant and large living
room, 1.0 to 2.0 is a concert hall, 5.0 is an amazingly large cavern, and values
larger than that quickly become unrealistic and metallic.</p>
<p>Most environments don't have the same decay time for all frequency bands, so the
FdnReverb actually uses a 3-band equalizer instead of raw gains on the feedback
paths.  The bands are as follows:</p>
<ul>
<li>0.0 to <code>SYZ_P_LATE_REFLECTIONS_LF_REFERENCE</code></li>
<li><code>SYZ_P_LATE_REFLECTIONS_LF_REFERENCE</code> to <code>SYZ_P_LATE_REFLECTIONS_HF_REFERENCE</code></li>
<li><code>SYZ_P_LATE_REFLECTIONS_HF_REFERENCE</code> to nyquist</li>
</ul>
<p><code>SYZ_P_T60</code> controls the decay time of the middle frequency band.  The lower
band is <code>t60 * lf_rolloff</code>, and the upper <code>t60 * hf_rolloff</code>.  This allows you
to simply change T60, and let the rolloff ratios control coloration.</p>
<p>Intuitively, rooms with carpet on all the walls have a rather low hf reference
and rolloff, and giant stone caverns are close to equal in all frequency bands.
The lf reference/rolloff pairing can be used primarily for non-natural base
boosting.  When the reverb starts, all frequencies are relatively equal but, as
the audio continually gets fed back through the feedback paths, the equalizer
will emphasize or deemphasize the 3 frequency bands at different rates.  To use
this effectively, treat the hf/lf as defining the materials of the wall, then
move t60.</p>
<p>Note that the amount of coloration you can get from the equalizer is limited
especially for short reverbs.  To control the perception of the environment more
bluntly and independently of t60, use the input filter.</p>
<h3 id="diffusion"><a class="header" href="#diffusion">Diffusion</a></h3>
<p>The diffusion of the reverb is how fast the reverb tail transitions from
discrete echoes to a continuous reverberant response.  Synthizer exposes this to
you as a percent-based control, since it's not conveniently possible to tie
anything to a real physical quantity in this case.  Typically, diffusion at 1.0
(the default) is what you want.</p>
<p>Another way to think of diffusion is how rough the walls are, how many obstacles
there are for sound to bounce off of, etc.</p>
<h3 id="delay-line-modulation"><a class="header" href="#delay-line-modulation">Delay Line modulation</a></h3>
<p>A problem with feedback delay networks and/or other allpass/comb filter reverb
designs is that they tend to be obviously periodic.  To deal with this,
modulation of the delay lines on the feedback path is often introduced.  The
final stage of designing an FdnReverb is to decide on the values of the
modulation depth and frequency.</p>
<p>The trade-off here is this:</p>
<ul>
<li>At low modulation depth/frequency, the reverb likes to sound metallic.</li>
<li>At high modulation depth/frequency, the reverb gains very obvious nonlinear
effects.</li>
<li>At very high modulation depth/frequency, the reverb doesn't sound like a
reverb at all.</li>
</ul>
<p>FdnReverb tries to default to universally applicable settings, but it might
still be worth adjusting these. To disable modulation all together, set the
depth to 0.0; due to internal details, setting the frequency to 0.0 is not
possible.</p>
<p>The artifacts introduced by large modulation depth/frequency values are least
noticeable with percussive sounds and most noticeable with constant tones such
as pianos and vocals.  Inversely, the periodic artifacts of no or little
modulation are most noticeable with percussive sounds and least  noticeable with
constant tones.</p>
<p>In general, the best way to not need to touch these settings is to use realistic
t60, as the beginning of the reverb isn't generally periodic.</p>
<h1 id="audio-eq-cookbook"><a class="header" href="#audio-eq-cookbook">Audio EQ Cookbook</a></h1>
<p>The following is the Audio EQ Cookbook, containing the most widely used formulas
for biquad filters.  Synthizer's internal implementation of most filters either
follows these exactly or is composed of cascaded/parallel sections.</p>
<p>There are several versions of this document on the web. This version is from
http://music.columbia.edu/pipermail/music-dsp/2001-March/041752.html.</p>
<pre><code>         Cookbook formulae for audio EQ biquad filter coefficients
---------------------------------------------------------------------------
by Robert Bristow-Johnson &lt;rbj at gisco.net&gt;  a.k.a. &lt;robert at audioheads.com&gt;


All filter transfer functions were derived from analog prototypes (that 
are shown below for each EQ filter type) and had been digitized using the 
Bilinear Transform.  BLT frequency warping has been taken into account 
for both significant frequency relocation and for bandwidth readjustment.

First, given a biquad transfer function defined as:

            b0 + b1*z^-1 + b2*z^-2
    H(z) = ------------------------                                (Eq 1)
            a0 + a1*z^-1 + a2*z^-2

This shows 6 coefficients instead of 5 so, depending on your architechture,
you will likely normalize a0 to be 1 and perhaps also b0 to 1 (and collect
that into an overall gain coefficient).  Then your transfer function would
look like:

            (b0/a0) + (b1/a0)*z^-1 + (b2/a0)*z^-2
    H(z) = ---------------------------------------                 (Eq 2)
               1 + (a1/a0)*z^-1 + (a2/a0)*z^-2

or

                      1 + (b1/b0)*z^-1 + (b2/b0)*z^-2
    H(z) = (b0/a0) * ---------------------------------             (Eq 3)
                      1 + (a1/a0)*z^-1 + (a2/a0)*z^-2


The most straight forward implementation would be the Direct I form (using Eq 2):

y[n] = (b0/a0)*x[n] + (b1/a0)*x[n-1] + (b2/a0)*x[n-2]
                    - (a1/a0)*y[n-1] - (a2/a0)*y[n-2]              (Eq 4)

This is probably both the best and the easiest method to implement in the 56K.



Now, given:

    sampleRate (the sampling frequency)

    frequency (&quot;wherever it's happenin', man.&quot;  &quot;center&quot; frequency 
        or &quot;corner&quot; (-3 dB) frequency, or shelf midpoint frequency, 
        depending on which filter type)
    
    dBgain (used only for peaking and shelving filters)

    bandwidth in octaves (between -3 dB frequencies for BPF and notch
        or between midpoint (dBgain/2) gain frequencies for peaking EQ)

     _or_ Q (the EE kind of definition)

     _or_ S, a &quot;shelf slope&quot; parameter (for shelving EQ only).  when S = 1, 
        the shelf slope is as steep as it can be and remain monotonically 
        increasing or decreasing gain with frequency.  the shelf slope, in 
        dB/octave, remains proportional to S for all other values.



First compute a few intermediate variables:

    A     = sqrt[ 10^(dBgain/20) ]
          = 10^(dBgain/40)                    (for peaking and shelving EQ filters only)

    omega = 2*PI*frequency/sampleRate

    sin   = sin(omega)
    cos   = cos(omega)

    alpha = sin/(2*Q)                                     (if Q is specified)
          = sin*sinh[ ln(2)/2 * bandwidth * omega/sin ]   (if bandwidth is specified)

    beta  = sqrt(A)/Q                                     (for shelving EQ filters only)
          = sqrt(A)*sqrt[ (A + 1/A)*(1/S - 1) + 2 ]       (if shelf slope is specified)
          = sqrt[ (A^2 + 1)/S - (A-1)^2 ]


Then compute the coefficients for whichever filter type you want:

  The analog prototypes are shown for normalized frequency.
  The bilinear transform substitutes:
  
                1          1 - z^-1
  s  &lt;-  -------------- * ----------
          tan(omega/2)     1 + z^-1

and makes use of these trig identities:

                    sin(w)
   tan(w/2)    = ------------
                  1 + cos(w)


                  1 - cos(w)
  (tan(w/2))^2 = ------------
                  1 + cos(w)



LPF:            H(s) = 1 / (s^2 + s/Q + 1)

                b0 =  (1 - cos)/2
                b1 =   1 - cos
                b2 =  (1 - cos)/2
                a0 =   1 + alpha
                a1 =  -2*cos
                a2 =   1 - alpha



HPF:            H(s) = s^2 / (s^2 + s/Q + 1)

                b0 =  (1 + cos)/2
                b1 = -(1 + cos)
                b2 =  (1 + cos)/2
                a0 =   1 + alpha
                a1 =  -2*cos
                a2 =   1 - alpha



BPF (constant skirt gain):    H(s) = s / (s^2 + s/Q + 1)

                b0 =   Q*alpha
                b1 =   0
                b2 =  -Q*alpha
                a0 =   1 + alpha
                a1 =  -2*cos
                a2 =   1 - alpha


BPF (constant peak gain):     H(s) = (s/Q) / (s^2 + s/Q + 1)

                b0 =   alpha
                b1 =   0
                b2 =  -alpha
                a0 =   1 + alpha
                a1 =  -2*cos
                a2 =   1 - alpha



notch:          H(s) = (s^2 + 1) / (s^2 + s/Q + 1)

                b0 =   1
                b1 =  -2*cos
                b2 =   1
                a0 =   1 + alpha
                a1 =  -2*cos
                a2 =   1 - alpha



APF:          H(s) = (s^2 - s/Q + 1) / (s^2 + s/Q + 1)

                b0 =   1 - alpha
                b1 =  -2*cos
                b2 =   1 + alpha
                a0 =   1 + alpha
                a1 =  -2*cos
                a2 =   1 - alpha



peakingEQ:      H(s) = (s^2 + s*(A/Q) + 1) / (s^2 + s/(A*Q) + 1)

                b0 =   1 + alpha*A
                b1 =  -2*cos
                b2 =   1 - alpha*A
                a0 =   1 + alpha/A
                a1 =  -2*cos
                a2 =   1 - alpha/A



lowShelf:       H(s) = A * (s^2 + beta*s + A) / (A*s^2 + beta*s + 1)

                b0 =    A*[ (A+1) - (A-1)*cos + beta*sin ]
                b1 =  2*A*[ (A-1) - (A+1)*cos            ]
                b2 =    A*[ (A+1) - (A-1)*cos - beta*sin ]
                a0 =        (A+1) + (A-1)*cos + beta*sin
                a1 =   -2*[ (A-1) + (A+1)*cos            ]
                a2 =        (A+1) + (A-1)*cos - beta*sin



highShelf:      H(s) = A * (A*s^2 + beta*s + 1) / (s^2 + beta*s + A)

                b0 =    A*[ (A+1) + (A-1)*cos + beta*sin ]
                b1 = -2*A*[ (A-1) + (A+1)*cos            ]
                b2 =    A*[ (A+1) + (A-1)*cos - beta*sin ]
                a0 =        (A+1) - (A-1)*cos + beta*sin
                a1 =    2*[ (A-1) - (A+1)*cos            ]
                a2 =        (A+1) - (A-1)*cos - beta*sin

</code></pre>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                

                
            </nav>

        </div>

        

        

        

        
        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        

        

        
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        
        
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
        
        

    </body>
</html>
